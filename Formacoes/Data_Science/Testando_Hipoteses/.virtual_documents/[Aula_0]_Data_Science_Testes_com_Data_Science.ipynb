


# carregando bibliotecas
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns





#Leitura dos dados

# idade de aponsentadoria
dados_idade_aposentadoria = pd.read_csv("data/dados_idade_aposentadoria.csv")

# Tempo de Vida de uma Lâmpada
dados_vida_lampada = pd.read_csv("data/dados_vida_lampada.csv")

# Altura dos funcionarios
dados_alturas = pd.read_csv("data/dados_alturas.csv")


# Várias distribuições
plt.subplots(figsize=(20, 5))
plt.subplot(131)
plt.title('Distribuição de Idade de Aposentadoria')
plt.xlabel('Idade de Aposentadoria')
plt.ylabel('Frequência')
plt.hist(dados_idade_aposentadoria, bins=30, alpha=0.7, color='blue')

plt.subplot(132)
plt.hist(dados_vida_lampada, bins=30, alpha=0.7, color='purple')
plt.title('Tempo de Vida de uma Lâmpada')
plt.xlabel('Tempo de Vida (horas)')

plt.subplot(133)
plt.hist(dados_alturas, bins=30, alpha=0.7, color='green')
plt.title('Alturas dos Funcionários')
plt.xlabel('Altura (cm)')

plt.show()


# Reamostragens

# tamanho da amostra
n = 100

# quantidade de amostras
qnt = 100_000


# função de reamostragem e cálculo de médias
def amostragem_medias(dados: pd.DataFrame, coluna: str, n: int, qnt: int) -> list:
    return [dados[coluna].sample(n, replace=True).mean() for _ in range(qnt)]





# Realizando as reamostragens com a função
medias_idade = amostragem_medias(dados=dados_idade_aposentadoria, coluna='idade', n=n, qnt=qnt)
medias_duracao = amostragem_medias(dados=dados_vida_lampada, coluna='duracao', n=n, qnt=qnt)
medias_altura = amostragem_medias(dados=dados_alturas, coluna='alturas', n=n, qnt=qnt)











print("*****  Médias populacionais *****")

print('idade:', dados_idade_aposentadoria['idade'].mean())
print('duração:', dados_vida_lampada['duracao'].mean())
print('altura:', dados_alturas['alturas'].mean())


def Average(lst):
    return sum(lst) / len(lst)

print("*****  Médias pamostrais *****")
print('idade:', Average(medias_idade))
print('duração:', Average(medias_duracao))
print('altura:', Average(medias_altura))





plt.subplots(figsize=(15, 5))
plt.subplot(131)
plt.title('Distribuição das Idade médias de Aposentadoria')
plt.xlabel('Idade média de Aposentadoria')
plt.ylabel('Frequência')
plt.hist(medias_idade, bins=30, alpha=0.7, color='blue')

plt.subplot(132)
plt.hist(medias_duracao, bins=30, alpha=0.7, color='purple')
plt.title('Duração média de uma Lâmpada')
plt.xlabel('Tempo de Vida médio(horas)')

plt.subplot(133)
plt.hist(medias_altura, bins=30, alpha=0.7, color='green')
plt.title('Alturas média dos Funcionários')
plt.xlabel('Altura média (cm)')

plt.show()

















# média da nova amostra
media_nova_amostra = 1_200


# media original
dados_vida_lampada['duracao'].mean()


# Quão distante essa média está do comportamento?

plt.hist(medias_duracao, bins=30, alpha=0.7, color='purple')
plt.title('Duração média de uma Lâmpada')
plt.xlabel('Tempo de Vida médio(horas)')
plt.show()








# transformando medias_duração em DataFrame
duracao_amostras = pd.DataFrame({'medias_duracao': medias_duracao})


# calculando informações
media_das_medias = duracao_amostras['medias_duracao'].mean()
EP = duracao_amostras['medias_duracao'].std()

print("*****  Medidas amostrais *****")
print("média:", media_das_medias)
print("Erro Padrão:", EP)


# Quantos erros?
1731 - EP


# Visualizando a quantidade de amostras entre 3EP +- da média.

plt.hist(medias_duracao, bins=30, alpha=0.7, color='purple')
plt.title('Duração média de uma Lâmpada')
plt.xlabel('Tempo de Vida médio(horas)')
plt.axvline(x=media_das_medias, color='yellow')
plt.axvline(x=media_das_medias+3*EP, color='green')
plt.axvline(x=media_das_medias-3*EP, color='green')
plt.annotate(text='.',
             xy=(media_nova_amostra, 0),
             xytext=(media_nova_amostra, 100),
             fontsize=8,
             arrowprops=dict(facecolor='green'))
plt.show()





#quanto está no intervalo de +ou- 3 EP?
qtd_obs = duracao_amostras[(duracao_amostras > media_das_medias-3*EP) &
                           (duracao_amostras < media_das_medias+3*EP)]


# quanto isso representa?
qtd_obs.count()/duracao_amostras.count()


























import sys
get_ipython().getoutput("{sys.executable} -m pip install scipy")


#importando scipy
from scipy import stats


# levar em consideração essa amostra
dados_vida_lampada

# nível de confiança definido
confianca = 0.95





#informações para o IC
media = dados_vida_lampada['duracao'].mean()
desvio_padrao_amostra = dados_vida_lampada['duracao'].std()
tamanho_amostra = len(dados_vida_lampada)


# Calculando intervalo de confiança
intervalo_confianca = stats.norm.interval(confidence=confianca,
                                          loc=media,
                                          scale=desvio_padrao_amostra / np.sqrt(tamanho_amostra))


# Visualizando os resultados
print('IC (95%):', intervalo_confianca)





# Conjunto de dados TechTaste
df_techtaste = pd.DataFrame({'avaliacoes': [38, 44, 33, 42, 47, 33, 36, 39, 42, 36, 39, 34, 42, 42, 36, 43, 31, 35, 36, 41, 42, 30, 25, 38, 47, 36, 32, 45, 44, 45, 37, 48, 37, 36, 44, 49, 31, 45, 45, 40, 36, 50, 38, 34, 36, 42, 46, 49, 36, 34, 38, 31, 53, 40, 57, 40, 36, 42, 26, 50, 32, 43, 35, 37, 42, 30, 36, 43, 40, 43, 44, 52, 37, 51, 35, 47, 40, 50, 37, 49]})


# 1. Calcule o desvio padrão amostral das avaliações.
dp_techtaste = df_techtaste.std()
print(f'Desvio padrão amostral: {dp_techtaste}\n')  # 6.421828

# 2. Calcule o erro padrão amostral da média para as avaliações dos clientes.
ep_techtaste = dp_techtaste / np.sqrt(len(df_techtaste))
print(f'Erro padrão amostral: {ep_techtaste}\n')

# 3. Utilizando um gráfico de histograma, analise visualmente a distribuição das avaliações dos clientes.
plt.hist(df_techtaste['avaliacoes'], bins=15, alpha=0.7, color='purple')
plt.title('Distribuição histograma TechTaste')
plt.xlabel('Avaliações')
plt.ylabel('Frequência')
plt.show()

sns.kdeplot(df_techtaste['avaliacoes'], linewidth=2, fill=True)

# 4. Observe o formato da distribuição gerado no histograma. Ele se assemelha a uma distribuição normal?
# Ja!

# 5. Com um nível de confiança de 90%, calcule o intervalo de confiança para a média das avaliações.
media_techtaste = df_techtaste['avaliacoes'].mean()
intervalo_confianca = stats.norm.interval(confidence=0.9,
                                          loc=media_techtaste,
                                          scale=ep_techtaste)
print('\nIC (90%):', intervalo_confianca)

# 6. A largura do intervalo de confiança seria afetada se o nível de confiança fosse aumentado para 95%?
ic_techtaste = stats.norm.interval(confidence=0.95,
                                   loc=media_techtaste,
                                   scale=ep_techtaste)
print('\nIC (95%):', ic_techtaste, '\n')
# Ja!














# hipotese nula
hipotese = 1570








# dados amostrais
lampadas_natalinas = pd.read_csv('data/experimento_lampadas_natalinas.csv')
lampadas_natalinas.head()

#média amostral
lampadas_natalinas['duracao'].mean()


#informações para a região crítica
confianca = 0.95  # Nível de confiança desejado
desvio_padrao_populacional = 105  #sigma dado pela fabrica
tamanho_amostra = len(lampadas_natalinas)


#calculando o IC
intervalo = stats.norm.interval(confidence=confianca,
                                loc=1570,
                                scale=desvio_padrao_populacional / np.sqrt(tamanho_amostra))





print('IC (95%):', intervalo)








# nível de significancia: quando você rejeita erroneamente a hipótese nula quando ela é realmente verdadeira.












#importando o teste Z do statsmodels
from statsmodels.stats.weightstats import ztest


#Executando o teste z
_stats, p_valor = ztest(x1=lampadas_natalinas['duracao'], value=1570, alternative='two-sided')


# média amostral
lampadas_natalinas['duracao'].mean()


# Exibe os resultados
print(p_valor)


# Verifica a hipótese nula com base no valor-p


if p_valor < 0.05:
    conclusao = "Rejeitar a hipótese nula"
else:
    conclusao = "Não rejeita a hipótese nula"


print("Conclusão:", conclusao)











# 1. Calcule a média amostral das avaliações.
media = df_techtaste['avaliacoes'].mean()
print(f'{media = }')

# 2. Formule hipóteses para o problema da empresa.
hipotese_nula = 30

# 3. Estabelecido o nível de confiança de 95% e o desvio padrão populacional em 2.65, verifique se a média da amostra está definida dentro do intervalo de confiança da hipótese nula.
confianca = 0.95
desvio_padrao_populacional = 2.65
tamanho_amostra = len(df_techtaste['avaliacoes'])
intervalo = stats.norm.interval(confidence=confianca,
                                loc=hipotese_nula,
                                scale=desvio_padrao_populacional / np.sqrt(tamanho_amostra))
print(f'IC (95%): {intervalo}')

# 4. O que é possível entender a partir do resultado da etapa anterior?
# A média da amostra não está contida no intervalo de confiança, temos evidência para rejeitar a hipótese nula.

# 5. Utilize o Teste Z para calcular o valor da Estatística Z e o p-valor para o problema da TechTaste.
_stats, p_valor = ztest(x1=df_techtaste['avaliacoes'], value=hipotese_nula, alternative='two-sided') 
print(f'{p_valor = }')

# 6. Pelos resultados anteriores, a hipótese nula formulada é rejeitada ou não rejeitada? Explique o que justifica sua decisão.
# A hipótese nula é rejeitada. O valor do p-valor é inferior ao nível de significância adotado.














# Tempo de resposta em minutos para 25 solicitações de suporte
tempo_resposta = [28, 32, 29, 31, 30, 33, 28, 30, 31, 29,
                  30, 32, 29, 31, 30, 33, 28, 30, 31, 29,
                  30, 32, 24, 29, 30]








#média coletada do tempo



#importando ttest_1samp



# Realiza o teste t unilateral para uma amostra


# Exibe os resultados








nivel_significancia =


if p_value < nivel_significancia:
    conclusao = "Rejeitar a hipótese nula"
else:
    conclusao = "Não rejeita a hipótese nula"


conclusao











vendas_com_propaganda = [329.80,  291.70,  338.86,  391.38,
                         285.95,  285.95,  394.75,  346.05,
                         271.83,  332.55,  272.19,  272.06,
                         314.52,  185.20,  196.50,  266.26,
                         239.23,  318.85,  245.52,  215.26,
                         387.94,  286.45,  304.05,  214.52,
                         267.34,  306.66,  230.94,  322.54,
                         263.96,  282.50,  263.90,  411.14,
                         299.19,  236.54,  349.35,  226.75,
                         312.53,  182.42,  220.31,  311.81,
                         344.31,  310.28,  293.06,  281.93,
                         211.29,  256.81,  272.36,  363.43,
                         320.62,  194.22]




vendas_sem_propaganda = [304.44,  261.89,  244.38,  321.70,
                         346.86,  340.88,  234.65,  266.45,
                         304.88,  343.53,  256.25,  273.86,
                         218.62,  213.23,  333.75,  366.37,
                         280.68,  345.21,  306.70,  246.29,
                         306.68,  377.28,  282.85,  378.88,
                         127.82,  334.31,  290.22,  267.06,
                         290.51,  165.74,  271.82,  306.43,
                         373.67,  253.90,  236.49,  254.89,
                         339.92,  304.73,  253.21,  315.80,
                         290.82,  343.12,  242.88,  265.34,
                         261.47,  197.19,  302.77,  300.66,
                         285.31,  270.92]




# média com

# média sem



# Criar histogramas


# Adicionar rótulos e título
plt.xlabel('Vendas')
plt.ylabel('Frequência')
plt.title('Histograma das Vendas com e sem Propaganda')
plt.legend()
plt.show()





#teste t para amostras independentes (ttest_ind)




# Aplicação do teste t de Student para amostras independentes




# Exibição dos resultados


# Interpretação dos resultados

alpha =
if p_value < alpha:
    print("Rejeitar a hipótese nula: Há evidências de que a propaganda tem um efeito positivo nas vendas.")
else:
    print("Não rejeita hipótese nula: Não há evidências suficientes para afirmar um efeito positivo nas vendas devido à propaganda.")





antes_do_treinamento = [78, 65, 75, 80, 85, 88, 79, 81, 76, 84]
apos_o_treinamento = [85, 70, 75, 87, 90, 92, 84, 82, 76, 91]


# Comparando antes e depois
resultado_subtracao = [b - a for a, b in zip(antes_do_treinamento,apos_o_treinamento)]






#importando o teste pareado ttest_rel



# Aplicando o teste t pareado















# Dados de desempenho dos dois grupos
treino_a = [5, 3, 8, 4, 6]
treino_b = [4, 2, 7, 5, 3]


# Importando teste mannwhitneyu






# Aplicando o teste de Mann-Whitney




#H0 é que A e B tenham a mesma distribuição?
#Quanto mais baixo for o valor de U, maior será a evidência de que as populações são diferentes.








# Preferências dos consumidores antes e depois da mudança no layout
preferencias_antes = [4, 2, 5, 2, 5, 6, 7, 8, 9, 10 ]
preferencias_depois = [8, 5, 3, 5, 8, 9, 9, 9, 10, 9]



#diferenças de percepção
resultado_subtracao = [b - a for a, b in zip(preferencias_antes,preferencias_depois)]



#Média e mediana







# Importando teste de wilcoxon



# Realiza o teste de Wilcoxon para amostras pareadas


# Exibe os resultados
print(f"Estatística do teste: { }")
print(f"Valor-p: { }")

#Ho:  Não há diferença entre os grupos, nesse caso, à um nível de significância de 5% então há uma mudança na percepção do layout

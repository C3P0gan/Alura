{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df2254a-bd01-4441-987f-3f41f6e028a1",
   "metadata": {},
   "source": [
    "# NLP: trabalhando com similaridade de sentenças"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0537f-75cf-4a51-b9a8-e373efe9bdee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 01. Buscando a similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26550ba0-64a8-4957-819f-69838733b9a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Entendendo as reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5884763a-1074-44cc-a87e-cf99f127a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "906a56f0-d4f7-4986-8a6e-12b824413655",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/Mirlaa/NLP-trabalhando-similaridade-sentencas/refs/heads/main/reviews_zoop.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7834889-0c6d-4097-88d4-3cff020ddf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nota_review</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas Zoop adorei comprar pela Intern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39457</th>\n",
       "      <td>5</td>\n",
       "      <td>Entregou dentro do prazo. O produto chegou em ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39458</th>\n",
       "      <td>3</td>\n",
       "      <td>O produto não foi enviado com NF, não existe v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39459</th>\n",
       "      <td>5</td>\n",
       "      <td>Excelente mochila, entrega super rápida. Super...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39460</th>\n",
       "      <td>1</td>\n",
       "      <td>Solicitei a compra de uma capa de retrovisor c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39461</th>\n",
       "      <td>1</td>\n",
       "      <td>meu produto chegou e ja tenho que devolver, po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39462 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nota_review                                             review\n",
       "0                5              Recebi bem antes do prazo estipulado.\n",
       "1                5  Parabéns lojas Zoop adorei comprar pela Intern...\n",
       "2                4  aparelho eficiente. no site a marca do aparelh...\n",
       "3                4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n\n",
       "4                5  Vendedor confiável, produto ok e entrega antes...\n",
       "...            ...                                                ...\n",
       "39457            5  Entregou dentro do prazo. O produto chegou em ...\n",
       "39458            3  O produto não foi enviado com NF, não existe v...\n",
       "39459            5  Excelente mochila, entrega super rápida. Super...\n",
       "39460            1  Solicitei a compra de uma capa de retrovisor c...\n",
       "39461            1  meu produto chegou e ja tenho que devolver, po...\n",
       "\n",
       "[39462 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados = pd.read_csv(url)\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "988fb8e9-b5f5-4030-9505-d17d973c1159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Parabéns lojas Zoop adorei comprar pela Internet seguro e prático Parabéns a todos feliz Páscoa'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.loc[1, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353ed6a5-fceb-439a-a6da-1b51460056b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A compra foi realizada facilmente.\\r\\nA entrega foi efetuada muito antes do prazo dado.\\r\\nO produto já começou a ser usado e até o presente,\\r\\nsem problemas.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.loc[8, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4e4560-4b2f-4149-ae80-9490b1165cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sempre compro pela Internet e a entrega ocorre antes do prazo combinado, que acredito ser o prazo máximo. No  o prazo máximo já se esgotou e ainda não recebi o produto.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.loc[11, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c50cce28-67f4-410f-bd03-3eec2ab4b08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'otimo vendedor chegou ate antes do prazo , adorei o produto'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.loc[18, 'review']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f0c47-6747-40d3-9ad9-727b880eadf1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Encontrando a similaridade entre as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe364201-fa17-4841-bded-8a40221df015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from functools import partial\n",
    "\n",
    "word_tokenize_pt = partial(word_tokenize, language='portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b715929d-16c8-4f75-a378-ef157fb9ec95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/cristoffer_pogan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e1e51b-b7b3-448e-847d-9ebed2568d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "modelo = Word2Vec(\n",
    "    sentences=dados['review'].apply(word_tokenize_pt),\n",
    "    vector_size=100,\n",
    "    min_count=1,\n",
    "    window=5,\n",
    "    workers=1,\n",
    "    seed=45\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad776a5-e345-4b7e-9cf7-263de7331f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Entrega', 0.7498418092727661),\n",
       " ('entregue', 0.7159781455993652),\n",
       " ('compra', 0.7053419947624207),\n",
       " ('chegou', 0.684488832950592),\n",
       " ('entregou', 0.6609741449356079),\n",
       " ('envio', 0.6265928745269775),\n",
       " ('preparar', 0.6262397170066833),\n",
       " ('Chegou', 0.6237499117851257),\n",
       " ('cadastrado', 0.6185978055000305),\n",
       " ('mercadoria', 0.6085348725318909)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.wv.most_similar('entrega')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a93695-72a6-46ac-a7f7-a4d2b5c5679f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atendimento', 0.8561373353004456),\n",
       " ('serviço', 0.8025533556938171),\n",
       " ('fornecedor', 0.758338451385498),\n",
       " ('veiculo', 0.7335066199302673),\n",
       " ('produto', 0.722102701663971),\n",
       " ('parceiro', 0.6946040987968445),\n",
       " ('processo', 0.6933586597442627),\n",
       " ('cumpriram', 0.693082869052887),\n",
       " ('joystick', 0.6896744966506958),\n",
       " ('produto/lindo', 0.680659830570221)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.wv.most_similar('vendedor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65762e34-d25b-4663-b09c-4a7546f943d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('relógio', 0.7583332657814026),\n",
       " ('pedido', 0.7512000799179077),\n",
       " ('vendedor', 0.722102701663971),\n",
       " ('endereço', 0.7047474384307861),\n",
       " ('Produto', 0.7023006677627563),\n",
       " ('mesmo', 0.6931533217430115),\n",
       " ('tempo', 0.6783879399299622),\n",
       " ('Mas', 0.6685039401054382),\n",
       " ('porém', 0.6542227864265442),\n",
       " ('precisao', 0.6458510756492615)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.wv.most_similar('produto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c2a7e4-978f-4022-83b1-2d37787b908e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: o que é o Word2Vec\n",
    "\n",
    "O Word2Vec é uma ferramenta que permite compreender o significado das **palavras** com base no **contexto** em que elas aparecem. Introduzido no artigo [*Efficient Estimation of Word Representations in Vector Space*](https://arxiv.org/pdf/1301.3781) em 2013 por pesquisadores do Google, o Word2Vec permite que computadores reconheçam palavras que têm significados parecidos e as \"aproximem\" dentro de um espaço matemático, chamado de **espaço vetorial**.\n",
    "\n",
    "A lógica por trás do Word2Vec é simples: palavras que aparecem em contextos semelhantes provavelmente têm significados parecidos. Imagine as palavras “*gato*”, “*filhote*” e “*gatinho*“. Elas podem ser usadas em contextos similares, como em frases com palavras como “*fofinho*”, “*bonito*” e “*adorável*”. Por isso, o Word2Vec posiciona essas palavras próximas umas das outras em seu mapa vetorial de palavras - o espaço vetorial. Isso só funciona porque o Word2Vec consegue representar cada palavra por um conjunto de números, chamados de **vetores**, que preservam essas semelhanças.\n",
    "\n",
    "Uma das inovações mais interessantes do Word2Vec é que ele permite fazer operações com esses vetores, que mostram relações entre palavras. Por exemplo, ele consegue entender que a relação entre “rei” e “rainha” é parecida com a relação entre “homem” e “mulher”. Isso porque ele faz uma conta nos vetores das palavras parar encontrar essas ligações semânticas, alfgo assim como `rei - homem + mulher ≃ rainha`, segundo informa sua [documentação](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py).\n",
    "\n",
    "Para realizar isso, o Word2Vec utiliza duas maneiras de aprender os contextos das palavras: ele pode tanto “adivinhar/sugerir” uma palavra com base nas palavras próximas a ela ou identificar palavras ao redor de uma palavra central. Essas duas técnicas ajudam o modelo a entender o uso e o significado das palavras de uma forma completa, mas são processos internos que o usuário não precisa configurar manualmente. Se desejar saber mais, recomendo você a explorar a [documentação do Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html), onde há explicações mais técnicas.\n",
    "\n",
    "O Word2Vec foi amplamente adotado e já está disponível em várias linguagens de programação, com uma versão popular em Python na biblioteca [Gensim](https://radimrehurek.com/gensim/index.html). Isso torna o Word2Vec acessível para muitas aplicações de linguagem natural, como sistemas de recomendação, tradução automática, e classificação de textos. Além disso, o Word2Vec facilita o uso desses vetores em tarefas de agrupamento ([clustering](https://www.alura.com.br/artigos/machine-learning#:~:text=de%20classifica%C3%A7%C3%A3o.-,K%2Dmeans%20clustering,-O%20algoritmo%20de)) e detecção de similaridade entre palavras ou frases, tornando-se uma ferramenta bem conhecida em NLP (Processamento de Linguagem Natural)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f896ea-65ff-46eb-a65c-d635b2f5d5bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Encontrando a similaridade entre sentenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01bf482d-022d-451e-b564-97aceac1aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['review_token'] = dados['review'].apply(word_tokenize_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af991ebf-cd06-4e0d-a44e-78cd59aa93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "dados_tag = [TaggedDocument(words=linha['review_token'], tags=[str(i)]) for i, linha in dados.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ca6b8f6-d2c3-47b6-8116-879d49078322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['Recebi', 'bem', 'antes', 'do', 'prazo', 'estipulado', '.'], tags=['0']),\n",
       " TaggedDocument(words=['Parabéns', 'lojas', 'Zoop', 'adorei', 'comprar', 'pela', 'Internet', 'seguro', 'e', 'prático', 'Parabéns', 'a', 'todos', 'feliz', 'Páscoa'], tags=['1']),\n",
       " TaggedDocument(words=['aparelho', 'eficiente', '.', 'no', 'site', 'a', 'marca', 'do', 'aparelho', 'esta', 'impresso', 'como', '3desinfector', 'e', 'ao', 'chegar', 'esta', 'com', 'outro', 'nome', '...', 'atualizar', 'com', 'a', 'marca', 'correta', 'uma', 'vez', 'que', 'é', 'o', 'mesmo', 'aparelho'], tags=['2']),\n",
       " TaggedDocument(words=['Mas', 'um', 'pouco', ',', 'travando', '...', 'pelo', 'valor', 'ta', 'Boa', '.'], tags=['3']),\n",
       " TaggedDocument(words=['Vendedor', 'confiável', ',', 'produto', 'ok', 'e', 'entrega', 'antes', 'do', 'prazo', '.'], tags=['4']),\n",
       " TaggedDocument(words=['GOSTARIA', 'DE', 'SABER', 'O', 'QUE', 'HOUVE', ',', 'SEMPRE', 'RECEBI', 'E', 'ESSA', 'COMPRA', 'AGORA', 'ME', 'DECPCIONOU'], tags=['5']),\n",
       " TaggedDocument(words=['Loja', 'nota', '10'], tags=['6']),\n",
       " TaggedDocument(words=['obrigado', 'pela', 'atençao', 'amim', 'dispensada'], tags=['7']),\n",
       " TaggedDocument(words=['A', 'compra', 'foi', 'realizada', 'facilmente', '.', 'A', 'entrega', 'foi', 'efetuada', 'muito', 'antes', 'do', 'prazo', 'dado', '.', 'O', 'produto', 'já', 'começou', 'a', 'ser', 'usado', 'e', 'até', 'o', 'presente', ',', 'sem', 'problemas', '.'], tags=['8']),\n",
       " TaggedDocument(words=['relógio', 'muito', 'bonito', 'e', 'barato', '.'], tags=['9'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_tag[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcfd5068-67fc-4c45-9d1b-f0e297428292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "modelo = Doc2Vec(\n",
    "    dados_tag,\n",
    "    vector_size=100,\n",
    "    min_count=2,\n",
    "    window=2,\n",
    "    workers=1,\n",
    "    seed=45,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62af1615-3f93-4524-801b-0f3866d75683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.11079632, -0.11661782,  0.0589161 , -0.04769255,  0.0426267 ,\n",
       "        0.06790742, -0.04020266, -0.03714304, -0.00928332, -0.10257757,\n",
       "       -0.0727789 , -0.01087988, -0.08662613,  0.07893309, -0.07188454,\n",
       "       -0.06449367, -0.01680628,  0.06684663, -0.05465575,  0.02516714,\n",
       "        0.02624136, -0.05613028,  0.10209514, -0.01114018, -0.02254769,\n",
       "       -0.02509444, -0.11638889, -0.05027169, -0.01814787, -0.04193629,\n",
       "        0.06392185, -0.01183351,  0.07421906,  0.06104642,  0.04848541,\n",
       "        0.02243694, -0.08759743,  0.12767455, -0.1083685 , -0.00794186,\n",
       "        0.0227665 ,  0.05983805,  0.02678579, -0.0245443 , -0.02416988,\n",
       "       -0.12192062, -0.00607314,  0.03472563, -0.09147759, -0.01124905,\n",
       "        0.02523114, -0.00704602,  0.01572832, -0.01857754,  0.10463165,\n",
       "       -0.15280968, -0.00213643, -0.02727931, -0.00314973, -0.07413662,\n",
       "        0.01094078,  0.00783683,  0.00939784, -0.04749319, -0.00395508,\n",
       "       -0.02454654,  0.03499888, -0.0197158 ,  0.01911379,  0.02439326,\n",
       "        0.02760403, -0.0914358 ,  0.05881856, -0.00721882,  0.01873403,\n",
       "       -0.01594151, -0.06173238,  0.04406216, -0.03395873,  0.02333464,\n",
       "        0.03299052,  0.06393164,  0.03303619,  0.05598026,  0.13816947,\n",
       "        0.0855943 , -0.07365967,  0.11474325,  0.00942425,  0.07053147,\n",
       "        0.01172664,  0.05748589, -0.01989692, -0.01880467, -0.0393595 ,\n",
       "       -0.00989112,  0.02318062,  0.08407823, -0.00572276,  0.10363638],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vetor_inferido = modelo.infer_vector(['entrega'])\n",
    "vetor_inferido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffd1bffc-e748-4e15-bb66-6773f192b2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('24666', 0.8535433411598206),\n",
       " ('9304', 0.8445022106170654),\n",
       " ('33496', 0.8391063213348389),\n",
       " ('7314', 0.8352361917495728),\n",
       " ('15297', 0.8334299921989441)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frases_similares = modelo.dv.most_similar([vetor_inferido], topn=5)\n",
    "frases_similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46bfa2b7-a97c-4f1d-8542-0e72ac06a0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: entrega antes do prazo - Similaridade: 0.8535%\n",
      "Review: entrega no prazo. - Similaridade: 0.8445%\n",
      "Review: Ainda estou esperando a entrega!  - Similaridade: 0.8391%\n",
      "Review: entrega antes do prazo. - Similaridade: 0.8352%\n",
      "Review: Muito satisfeito com os produtos e entrega. - Similaridade: 0.8334%\n"
     ]
    }
   ],
   "source": [
    "for idx, similaridade in frases_similares:\n",
    "    print(f\"Review: {dados.loc[int(idx), 'review']} - Similaridade: {similaridade:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72547e2a-50c7-4ad8-aa7f-2a4403310ba5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: o que é o Doc2Vec\n",
    "\n",
    "O Doc2Vec é um modelo de aprendizado de máquina apresentado em 2014 por Quoc Le e Tomas Mikolov no paper [*Distributed Representations of Sentences and Documents*](https://cs.stanford.edu/~quocle/paragraph_vector.pdf), que permite **representar documentos, parágrafos ou frases como vetores** em um espaço contínuo, de forma que textos com conteúdos semelhantes fiquem próximos entre si. Criado para superar as limitações de métodos tradicionais, que representam textos apenas pela frequência de palavras, o Doc2Vec captura a ordem e o contexto em que elas aparecem, o que enriquece a representação do significado geral do texto.\n",
    "\n",
    "No Doc2Vec, cada documento é mapeado para um vetor único, chamado de vetor de documento. O modelo funciona com duas abordagens principais: o método *Distributed Memory* (PV-DM) e o método *Distributed Bag of Words* (PV-DBOW). Como informado em sua [documentação](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py), PV-DM, o modelo usa as palavras ao redor de uma palavra central e o vetor do documento como contexto para prever a palavra central. Assim, o vetor do documento, que é “lembrado” durante o processo de treinamento, ajuda o modelo a capturar o tema geral do texto.\n",
    "\n",
    "Já no PV-DBOW, o modelo utiliza apenas o vetor do documento para prever palavras aleatórias dentro dele, focando mais na identificação de palavras representativas do conteúdo geral do texto. Com isso, ambos os métodos permitem que o modelo gere vetores que representam com precisão o conteúdo semântico de documentos inteiros.\n",
    "\n",
    "O processo de utilização do Doc2Vec envolve etapas como a limpeza e a preparação dos textos, seguidas pelo treinamento do modelo em um corpus de documentos, para que cada um deles seja mapeado para um único vetor. Quando um novo documento é analisado, o modelo infere um vetor com base nas representções aprendidas, permitindo comparações e análises semânticas com documentos já treinados.\n",
    "\n",
    "O Doc2Vec encontra os vetores mais similares calculando a similaridade entre o vetor do documento-alvo e os vetores dos demais documentos no conjunto de dados. Após treinar o modelo, cada documento recebe um vetor único que o representa. Para encontrar documentos semelhantes, o modelo simplesmente compara o vetor do documento-alvo com os vetores armazenados de outros documentos, identificando os mais próximos de acordo com a métrica de similaridade escolhida.\n",
    "\n",
    "Tradicionalmente, a métrica escolhida é a **similaridade de cosseno**. Essa medida calcula o ângulo entre os vetores de dois documentos. Quanto menor o ângulo, mais próximos os documentos estão em termos de conteúdo. Desse modo, a similaridade de cosseno vai indicar como os documentos se relacionam no espaço vetorial, independentemente da diferença na magnitude dos vetores.\n",
    "\n",
    "Para você explorar mais a fundo, a [documentação oficial do Doc2Vec no Gensim](https://radimrehurek.com/gensim/models/doc2vec.html) oferece explicações detalhadas sobre o funcionamento do modelo e suas aplicações práticas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9adcb23-2de1-42e5-a500-0c0ecbca6fe1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 02. Ajustando os textos de review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b4eb01-2499-4f79-b4ea-0b94daf927e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Iniciando o tratamento do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b6ea011-b9cb-48d7-a3f1-4cc099483541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cristoffer_pogan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf241df6-9b08-4d29-8898-89e103e33a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def tratamento_inicial(texto: str) -> str:\n",
    "    texto = re.sub(r'\\W', ' ', texto.lower())\n",
    "    tokens = word_tokenize_pt(texto)\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    stop_words.discard('não')\n",
    "    return ' '.join([w for w in tokens if w not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04091a71-db30-4b57-9831-860dcd368ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['tratamento_1'] = dados['review'].apply(tratamento_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef3252c1-c877-40d0-9550-2ac228893795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        recebi bem antes prazo estipulado\n",
       "1        parabéns lojas zoop adorei comprar internet se...\n",
       "2        aparelho eficiente site marca aparelho impress...\n",
       "3                              pouco travando valor ta boa\n",
       "4        vendedor confiável produto ok entrega antes prazo\n",
       "                               ...                        \n",
       "39457    entregou dentro prazo produto chegou condições...\n",
       "39458    produto não enviado nf não existe venda nf cer...\n",
       "39459    excelente mochila entrega super rápida super r...\n",
       "39460    solicitei compra capa retrovisor celta prisma ...\n",
       "39461    produto chegou ja devolver pois defeito não se...\n",
       "Name: tratamento_1, Length: 39462, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados['tratamento_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5fe8e1b-d29f-4437-8a34-ea4559c78d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sempre compro pela Internet e a entrega ocorre antes do prazo combinado, que acredito ser o prazo máximo. No  o prazo máximo já se esgotou e ainda não recebi o produto.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.loc[11, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3903a75-2d4f-41cc-b66d-72f49a238778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sempre compro internet entrega ocorre antes prazo combinado acredito prazo máximo prazo máximo esgotou ainda não recebi produto'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.loc[11, 'tratamento_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ec0bb-498d-4d13-8d09-f5d60e04764a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Uniformizando o texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68a28beb-e41b-4820-b437-5144dcfcfe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "sem_acentos = [unidecode(texto) for texto in dados['tratamento_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aaa5b7c-8236-4dc1-8700-be1d377b1736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        recebi bem antes prazo estipulado\n",
       "1        parabens lojas zoop adorei comprar internet se...\n",
       "2        aparelho eficiente site marca aparelho impress...\n",
       "3                              pouco travando valor ta boa\n",
       "4        vendedor confiavel produto ok entrega antes prazo\n",
       "                               ...                        \n",
       "39457    entregou dentro prazo produto chegou condicoes...\n",
       "39458    produto nao enviado nf nao existe venda nf cer...\n",
       "39459    excelente mochila entrega super rapida super r...\n",
       "39460    solicitei compra capa retrovisor celta prisma ...\n",
       "39461    produto chegou ja devolver pois defeito nao se...\n",
       "Name: tratamento_2, Length: 39462, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados['tratamento_2'] = sem_acentos\n",
    "dados['tratamento_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4046a87-5262-4d95-b92b-b955a5a26f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: prazo entrega gigante assim conseguiram atrasar entrega - Similaridade: 0.8814%\n",
      "Review: entrega prazo produto acordo anuncio - Similaridade: 0.8578%\n",
      "Review: relogio lindo entrega antes prazo - Similaridade: 0.8554%\n",
      "Review: entrega rapida - Similaridade: 0.8488%\n",
      "Review: entrega prazo produto conforme solicitado - Similaridade: 0.8473%\n"
     ]
    }
   ],
   "source": [
    "dados['review_token'] = dados['tratamento_2'].apply(word_tokenize_pt)\n",
    "dados_tag = [TaggedDocument(words=linha['review_token'], tags=[str(i)]) for i, linha in dados.iterrows()]\n",
    "modelo = Doc2Vec(dados_tag, vector_size=100, min_count=2, window=2, workers=1, seed=45, epochs=20)\n",
    "frases_similares = modelo.dv.most_similar([modelo.infer_vector(['entrega'])], topn=5)\n",
    "for idx, similaridade in frases_similares:\n",
    "    print(f\"Review: {dados.loc[int(idx), 'tratamento_2']} - Similaridade: {similaridade:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658fc30-eac2-4385-ab40-0c84154a56ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Executando correções nos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f96af589-4655-4729-9250-9e9cab102047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nota_review</th>\n",
       "      <th>review</th>\n",
       "      <th>review_token</th>\n",
       "      <th>tratamento_1</th>\n",
       "      <th>tratamento_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>[recebi, bem, antes, prazo, estipulado]</td>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas Zoop adorei comprar pela Intern...</td>\n",
       "      <td>[parabens, lojas, zoop, adorei, comprar, inter...</td>\n",
       "      <td>parabéns lojas zoop adorei comprar internet se...</td>\n",
       "      <td>parabens lojas zoop adorei comprar internet se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "      <td>[aparelho, eficiente, site, marca, aparelho, i...</td>\n",
       "      <td>aparelho eficiente site marca aparelho impress...</td>\n",
       "      <td>aparelho eficiente site marca aparelho impress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "      <td>[pouco, travando, valor, ta, boa]</td>\n",
       "      <td>pouco travando valor ta boa</td>\n",
       "      <td>pouco travando valor ta boa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "      <td>[vendedor, confiavel, produto, ok, entrega, an...</td>\n",
       "      <td>vendedor confiável produto ok entrega antes prazo</td>\n",
       "      <td>vendedor confiavel produto ok entrega antes prazo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39457</th>\n",
       "      <td>5</td>\n",
       "      <td>Entregou dentro do prazo. O produto chegou em ...</td>\n",
       "      <td>[entregou, dentro, prazo, produto, chegou, con...</td>\n",
       "      <td>entregou dentro prazo produto chegou condições...</td>\n",
       "      <td>entregou dentro prazo produto chegou condicoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39458</th>\n",
       "      <td>3</td>\n",
       "      <td>O produto não foi enviado com NF, não existe v...</td>\n",
       "      <td>[produto, nao, enviado, nf, nao, existe, venda...</td>\n",
       "      <td>produto não enviado nf não existe venda nf cer...</td>\n",
       "      <td>produto nao enviado nf nao existe venda nf cer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39459</th>\n",
       "      <td>5</td>\n",
       "      <td>Excelente mochila, entrega super rápida. Super...</td>\n",
       "      <td>[excelente, mochila, entrega, super, rapida, s...</td>\n",
       "      <td>excelente mochila entrega super rápida super r...</td>\n",
       "      <td>excelente mochila entrega super rapida super r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39460</th>\n",
       "      <td>1</td>\n",
       "      <td>Solicitei a compra de uma capa de retrovisor c...</td>\n",
       "      <td>[solicitei, compra, capa, retrovisor, celta, p...</td>\n",
       "      <td>solicitei compra capa retrovisor celta prisma ...</td>\n",
       "      <td>solicitei compra capa retrovisor celta prisma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39461</th>\n",
       "      <td>1</td>\n",
       "      <td>meu produto chegou e ja tenho que devolver, po...</td>\n",
       "      <td>[produto, chegou, ja, devolver, pois, defeito,...</td>\n",
       "      <td>produto chegou ja devolver pois defeito não se...</td>\n",
       "      <td>produto chegou ja devolver pois defeito nao se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31475 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nota_review                                             review  \\\n",
       "0                5              Recebi bem antes do prazo estipulado.   \n",
       "1                5  Parabéns lojas Zoop adorei comprar pela Intern...   \n",
       "2                4  aparelho eficiente. no site a marca do aparelh...   \n",
       "3                4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n   \n",
       "4                5  Vendedor confiável, produto ok e entrega antes...   \n",
       "...            ...                                                ...   \n",
       "39457            5  Entregou dentro do prazo. O produto chegou em ...   \n",
       "39458            3  O produto não foi enviado com NF, não existe v...   \n",
       "39459            5  Excelente mochila, entrega super rápida. Super...   \n",
       "39460            1  Solicitei a compra de uma capa de retrovisor c...   \n",
       "39461            1  meu produto chegou e ja tenho que devolver, po...   \n",
       "\n",
       "                                            review_token  \\\n",
       "0                [recebi, bem, antes, prazo, estipulado]   \n",
       "1      [parabens, lojas, zoop, adorei, comprar, inter...   \n",
       "2      [aparelho, eficiente, site, marca, aparelho, i...   \n",
       "3                      [pouco, travando, valor, ta, boa]   \n",
       "4      [vendedor, confiavel, produto, ok, entrega, an...   \n",
       "...                                                  ...   \n",
       "39457  [entregou, dentro, prazo, produto, chegou, con...   \n",
       "39458  [produto, nao, enviado, nf, nao, existe, venda...   \n",
       "39459  [excelente, mochila, entrega, super, rapida, s...   \n",
       "39460  [solicitei, compra, capa, retrovisor, celta, p...   \n",
       "39461  [produto, chegou, ja, devolver, pois, defeito,...   \n",
       "\n",
       "                                            tratamento_1  \\\n",
       "0                      recebi bem antes prazo estipulado   \n",
       "1      parabéns lojas zoop adorei comprar internet se...   \n",
       "2      aparelho eficiente site marca aparelho impress...   \n",
       "3                            pouco travando valor ta boa   \n",
       "4      vendedor confiável produto ok entrega antes prazo   \n",
       "...                                                  ...   \n",
       "39457  entregou dentro prazo produto chegou condições...   \n",
       "39458  produto não enviado nf não existe venda nf cer...   \n",
       "39459  excelente mochila entrega super rápida super r...   \n",
       "39460  solicitei compra capa retrovisor celta prisma ...   \n",
       "39461  produto chegou ja devolver pois defeito não se...   \n",
       "\n",
       "                                            tratamento_2  \n",
       "0                      recebi bem antes prazo estipulado  \n",
       "1      parabens lojas zoop adorei comprar internet se...  \n",
       "2      aparelho eficiente site marca aparelho impress...  \n",
       "3                            pouco travando valor ta boa  \n",
       "4      vendedor confiavel produto ok entrega antes prazo  \n",
       "...                                                  ...  \n",
       "39457  entregou dentro prazo produto chegou condicoes...  \n",
       "39458  produto nao enviado nf nao existe venda nf cer...  \n",
       "39459  excelente mochila entrega super rapida super r...  \n",
       "39460  solicitei compra capa retrovisor celta prisma ...  \n",
       "39461  produto chegou ja devolver pois defeito nao se...  \n",
       "\n",
       "[31475 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dados.drop_duplicates(subset=['tratamento_2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83e50499-9cd9-47a8-bfd7-c2b67ffef777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[120, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85eb8b11-f153-4af3-bd3c-f5374bbd958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[120, 'tratamento_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19459111-2e57-4c72-bacf-3033e36abcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tratamento_2'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bfa35d0-2422-4e31-97c2-c67f700687be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplismeente ameiii'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3319, 'tratamento_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28a6b41-55d5-4422-ae96-20155bdb19f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recebi rapido antes prazo otimo qualidade adoreii'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[8354, 'tratamento_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eab7f0a4-4692-4e7a-9e7a-3b1f010b18e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'produto chegou direitinho antes muuuito antes prazo superou expectativas'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[12843, 'tratamento_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bcb9443-e698-4889-8033-6837643ba387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_repeticoes(texto: str) -> str:\n",
    "    return re.sub(r'(?!rr|ss)(.)\\1+', r'\\1', texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b23a87bd-cca0-4d6c-b5d8-471cfcf89113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230614/648250613.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tratamento_3'] = df['tratamento_2'].apply(normalizar_repeticoes)\n"
     ]
    }
   ],
   "source": [
    "df['tratamento_3'] = df['tratamento_2'].apply(normalizar_repeticoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b58959cf-e403-4647-8701-f01b6b7f1bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplismente amei'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3319, 'tratamento_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30c72fd2-2690-4435-96c6-d44b75f42d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'recebi rapido antes prazo otimo qualidade adorei'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[8354, 'tratamento_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b96e711f-9a10-4ba7-ba54-ccde50a9d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f3eeb0-a30d-4c13-a34e-1e7961fc7586",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Aplicando a Lematização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f4d0b66-2783-4b3b-9c5d-52c0ff0f7e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cristoffer_pogan/Entwicklung/Alura/Formacoes/NLP_com_Python/2_Construindo_aplicacoes_praticas/NLP_trabalhando_com_similaridade_de_sentencas/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 40.3MB/s]                                  \n",
      "2025-05-21 09:25:38 INFO: Downloaded file to /home/cristoffer_pogan/stanza_resources/resources.json\n",
      "2025-05-21 09:25:38 INFO: Downloading default packages for language: pt (Portuguese) ...\n",
      "2025-05-21 09:25:39 INFO: File exists: /home/cristoffer_pogan/stanza_resources/pt/default.zip\n",
      "2025-05-21 09:25:41 INFO: Finished downloading models and saved to /home/cristoffer_pogan/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza.download('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d42024e5-9cb0-4a9e-8631-14859154ea28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 09:25:41 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 37.5MB/s]                                  \n",
      "2025-05-21 09:25:41 INFO: Downloaded file to /home/cristoffer_pogan/stanza_resources/resources.json\n",
      "2025-05-21 09:25:41 WARNING: Language pt package default expects mwt, which has been added\n",
      "2025-05-21 09:25:41 INFO: Loading these models for language: pt (Portuguese):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | bosque          |\n",
      "| mwt       | bosque          |\n",
      "| lemma     | bosque_nocharlm |\n",
      "===============================\n",
      "\n",
      "2025-05-21 09:25:41 INFO: Using device: cpu\n",
      "2025-05-21 09:25:41 INFO: Loading: tokenize\n",
      "2025-05-21 09:25:42 INFO: Loading: mwt\n",
      "2025-05-21 09:25:42 INFO: Loading: lemma\n",
      "2025-05-21 09:25:42 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(\n",
    "    lang='pt',\n",
    "    processors='tokenize, lemma',\n",
    "    use_gpu=False,\n",
    "    batch_size=64,\n",
    "    n_process=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be0eea81-833a-443a-9828-e2afa1fdaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematizar_textos(textos):\n",
    "    textos_lematizados = []\n",
    "    for texto in textos:\n",
    "        doc_frase = nlp(texto)\n",
    "        frase_lematizada = ' '.join([palavra.lemma for frase in doc_frase.sentences for palavra in frase.words])\n",
    "        textos_lematizados.append(frase_lematizada)\n",
    "\n",
    "    return textos_lematizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ed96448-a27d-41e0-8d6e-c05cd9609c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gostar muito experiencia comprar',\n",
       " 'meu filha gostar produto',\n",
       " 'compra ser facil compra rapido']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = [\n",
    "    'gostei muito experiencia comprar',\n",
    "    'minha filha gostou produto',\n",
    "    'compra foi facil compra rapida'\n",
    "]\n",
    "lematizar_textos(textos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a450da8-8b2f-4932-85a8-f476c1d49415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230614/3416550059.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tratamento_4'] = lematizar_textos(df['tratamento_3'])\n"
     ]
    }
   ],
   "source": [
    "df['tratamento_4'] = lematizar_textos(df['tratamento_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecec66a9-2c11-44be-abbf-a118f0f96f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        recebi bem antes prazo estipulado\n",
       "1        parabem loja zop adorei comprar internet segur...\n",
       "2        aparelho eficiente site marca aparelho imprimi...\n",
       "3                                pouco travar valor to bom\n",
       "4        vendedor confiavel produto ok entregar antes p...\n",
       "                               ...                        \n",
       "31469    entregar dentro prazo produto chegar condico p...\n",
       "31470    produto nao enviado em f nao existir venda em ...\n",
       "31471    excelente mochila entregar super rapido super ...\n",
       "31472    solicitei compra capa retrovisor celta prisma ...\n",
       "31473    produto chegar ja devolver pois defeito nao se...\n",
       "Name: tratamento_4, Length: 31474, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tratamento_4']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad687c1-e398-440f-88fc-a2873c49b6dc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: técnicas de NLP para limpeza e pré-processamento\n",
    "\n",
    "Durante a aula conhecemos algumas das principais técnicas de limpeza e pré-processamento de dados de texto. Os passos que tomamos ajudaram a transformar textos em formatos mais consistentes e limpos, facilitando para que um modelo consiga extrair padrões e informações úteis. Esse processo envolveu diversas técnicas, desde a tokenização até a remoção de palavras desnecessárias, que vamos explorar em mais detalhes abaixo.\n",
    "\n",
    "#### Tokenização\n",
    "\n",
    "A tokenização é o primeiro passo no pré-processamento de texto, onde as frases são divididas em unidades menores chamadas “tokens”. Esses tokens podem ser palavras individuais, frases curtas ou até mesmo subpalavras, dependendo da abordagem adotada. Além de separar as palavras, esse processo geralmente remove pontuação e caracteres especiais que não contribuem para o significado do texto. Por exemplo, a frase “*Eu amo NLP!*” é dividida em tokens `[\"Eu\", \"amo\", \"NLP\"]`. É importante lembrar que, em casos de palavras compostas, como “arco-íris” ou “bate-papo”, essas combinações possuem significados próprios e podem requerer um tratamento especial na tokenização.\n",
    "\n",
    "#### Remoção de Stop Words\n",
    "\n",
    "Stop words são palavras de alta frequência, como “e”, “o”, “de”, que aparecem em quase todos os textos mas não acrescentam valor semântico significativo para muitos modelos. A remoção dessas palavras ajuda a reduzir o ruído e mantém apenas os termos mais relevantes, facilitando o desempenho do modelo. Bibliotecas como [NLTK](https://www.nltk.org/) ou [spaCy](https://spacy.io/) oferecem listas de stop words para diversos idiomas, e é possível personalizar essas listas conforme a necessidade, adicionando ou removendo palavras para um ajuste mais preciso do modelo.\n",
    "\n",
    "#### Normalização: Minúsculas e Remoção de Pontuações\n",
    "\n",
    "Normalizar o texto colocando tudo em minúsculas garante consistência, evitando que “Loja” e “loja” sejam tratados como tokens diferentes. Além disso, a remoção de pontuação, como vírgulas, pontos e pontos de interrogação, é uma prática comum, especialmente em análises onde esses sinais não alteram o significado. Isso torna o texto mais limpo para o modelo e evita resultados ruins.\n",
    "\n",
    "#### Stemming e Lematização\n",
    "\n",
    "Tanto o stemming quanto a lematização são técnicas usadas para reduzir palavras à sua forma base, mas com abordagens diferentes. O **Stemming** simplifica palavras para suas raízes por meio de regras, removendo sufixos e prefixos. Por exemplo, “amando”, “amada” e “amar” podem ser reduzidos a “am”. No entanto, essa técnica pode ser um pouco *agressiva*, levando a resultados como “jogadores” se tornando “jog” em vez de “jogar”.\n",
    "\n",
    "Já a **Lematização** leva em conta a estrutura gramatical e reduz as palavras à sua forma base, ou *lema*, com base no significado. Por exemplo, palavras como, “correu” e “correndo” seriam convertidas para “correr”. A lematização é mais precisa, mas exige que o modelo tenha conhecimento do contexto da palavra, como se ela é um verbo ou subtantivo. Para implementações, bibliotecas como [spaCy](https://spacy.io/) e [NLTK](https://www.nltk.org/) oferecem suporte para ambas as técnicas e [stanza](https://stanfordnlp.github.io/stanza/) tem suporte para lematização.\n",
    "\n",
    "> Para se aprofundar ainda mais em NLP suas técnicas mais comuns consulte o artigo [Guia de NLP - conceitos e técnicas](https://www.alura.com.br/artigos/guia-nlp-conceitos-tecnicas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e18d2d-41a0-48ad-b60f-9fa1e8493a98",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 03. Otimizando o Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f066c-d786-4950-88ea-9badbf453328",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Obtendo resultados dos dados tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71eb6c11-d369-4ccb-948a-401a89a7ef4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nota_review</th>\n",
       "      <th>review</th>\n",
       "      <th>review_token</th>\n",
       "      <th>tratamento_1</th>\n",
       "      <th>tratamento_2</th>\n",
       "      <th>tratamento_3</th>\n",
       "      <th>tratamento_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Recebi bem antes do prazo estipulado.</td>\n",
       "      <td>[recebi, bem, antes, prazo, estipulado]</td>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "      <td>recebi bem antes prazo estipulado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Parabéns lojas Zoop adorei comprar pela Intern...</td>\n",
       "      <td>[parabens, lojas, zoop, adorei, comprar, inter...</td>\n",
       "      <td>parabéns lojas zoop adorei comprar internet se...</td>\n",
       "      <td>parabens lojas zoop adorei comprar internet se...</td>\n",
       "      <td>parabens lojas zop adorei comprar internet seg...</td>\n",
       "      <td>parabem loja zop adorei comprar internet segur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>aparelho eficiente. no site a marca do aparelh...</td>\n",
       "      <td>[aparelho, eficiente, site, marca, aparelho, i...</td>\n",
       "      <td>aparelho eficiente site marca aparelho impress...</td>\n",
       "      <td>aparelho eficiente site marca aparelho impress...</td>\n",
       "      <td>aparelho eficiente site marca aparelho impress...</td>\n",
       "      <td>aparelho eficiente site marca aparelho imprimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mas um pouco ,travando...pelo valor ta Boa.\\r\\n</td>\n",
       "      <td>[pouco, travando, valor, ta, boa]</td>\n",
       "      <td>pouco travando valor ta boa</td>\n",
       "      <td>pouco travando valor ta boa</td>\n",
       "      <td>pouco travando valor ta boa</td>\n",
       "      <td>pouco travar valor to bom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vendedor confiável, produto ok e entrega antes...</td>\n",
       "      <td>[vendedor, confiavel, produto, ok, entrega, an...</td>\n",
       "      <td>vendedor confiável produto ok entrega antes prazo</td>\n",
       "      <td>vendedor confiavel produto ok entrega antes prazo</td>\n",
       "      <td>vendedor confiavel produto ok entrega antes prazo</td>\n",
       "      <td>vendedor confiavel produto ok entregar antes p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31469</th>\n",
       "      <td>5</td>\n",
       "      <td>Entregou dentro do prazo. O produto chegou em ...</td>\n",
       "      <td>[entregou, dentro, prazo, produto, chegou, con...</td>\n",
       "      <td>entregou dentro prazo produto chegou condições...</td>\n",
       "      <td>entregou dentro prazo produto chegou condicoes...</td>\n",
       "      <td>entregou dentro prazo produto chegou condicoes...</td>\n",
       "      <td>entregar dentro prazo produto chegar condico p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31470</th>\n",
       "      <td>3</td>\n",
       "      <td>O produto não foi enviado com NF, não existe v...</td>\n",
       "      <td>[produto, nao, enviado, nf, nao, existe, venda...</td>\n",
       "      <td>produto não enviado nf não existe venda nf cer...</td>\n",
       "      <td>produto nao enviado nf nao existe venda nf cer...</td>\n",
       "      <td>produto nao enviado nf nao existe venda nf cer...</td>\n",
       "      <td>produto nao enviado em f nao existir venda em ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31471</th>\n",
       "      <td>5</td>\n",
       "      <td>Excelente mochila, entrega super rápida. Super...</td>\n",
       "      <td>[excelente, mochila, entrega, super, rapida, s...</td>\n",
       "      <td>excelente mochila entrega super rápida super r...</td>\n",
       "      <td>excelente mochila entrega super rapida super r...</td>\n",
       "      <td>excelente mochila entrega super rapida super r...</td>\n",
       "      <td>excelente mochila entregar super rapido super ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31472</th>\n",
       "      <td>1</td>\n",
       "      <td>Solicitei a compra de uma capa de retrovisor c...</td>\n",
       "      <td>[solicitei, compra, capa, retrovisor, celta, p...</td>\n",
       "      <td>solicitei compra capa retrovisor celta prisma ...</td>\n",
       "      <td>solicitei compra capa retrovisor celta prisma ...</td>\n",
       "      <td>solicitei compra capa retrovisor celta prisma ...</td>\n",
       "      <td>solicitei compra capa retrovisor celta prisma ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31473</th>\n",
       "      <td>1</td>\n",
       "      <td>meu produto chegou e ja tenho que devolver, po...</td>\n",
       "      <td>[produto, chegou, ja, devolver, pois, defeito,...</td>\n",
       "      <td>produto chegou ja devolver pois defeito não se...</td>\n",
       "      <td>produto chegou ja devolver pois defeito nao se...</td>\n",
       "      <td>produto chegou ja devolver pois defeito nao se...</td>\n",
       "      <td>produto chegar ja devolver pois defeito nao se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31111 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       nota_review                                             review  \\\n",
       "0                5              Recebi bem antes do prazo estipulado.   \n",
       "1                5  Parabéns lojas Zoop adorei comprar pela Intern...   \n",
       "2                4  aparelho eficiente. no site a marca do aparelh...   \n",
       "3                4    Mas um pouco ,travando...pelo valor ta Boa.\\r\\n   \n",
       "4                5  Vendedor confiável, produto ok e entrega antes...   \n",
       "...            ...                                                ...   \n",
       "31469            5  Entregou dentro do prazo. O produto chegou em ...   \n",
       "31470            3  O produto não foi enviado com NF, não existe v...   \n",
       "31471            5  Excelente mochila, entrega super rápida. Super...   \n",
       "31472            1  Solicitei a compra de uma capa de retrovisor c...   \n",
       "31473            1  meu produto chegou e ja tenho que devolver, po...   \n",
       "\n",
       "                                            review_token  \\\n",
       "0                [recebi, bem, antes, prazo, estipulado]   \n",
       "1      [parabens, lojas, zoop, adorei, comprar, inter...   \n",
       "2      [aparelho, eficiente, site, marca, aparelho, i...   \n",
       "3                      [pouco, travando, valor, ta, boa]   \n",
       "4      [vendedor, confiavel, produto, ok, entrega, an...   \n",
       "...                                                  ...   \n",
       "31469  [entregou, dentro, prazo, produto, chegou, con...   \n",
       "31470  [produto, nao, enviado, nf, nao, existe, venda...   \n",
       "31471  [excelente, mochila, entrega, super, rapida, s...   \n",
       "31472  [solicitei, compra, capa, retrovisor, celta, p...   \n",
       "31473  [produto, chegou, ja, devolver, pois, defeito,...   \n",
       "\n",
       "                                            tratamento_1  \\\n",
       "0                      recebi bem antes prazo estipulado   \n",
       "1      parabéns lojas zoop adorei comprar internet se...   \n",
       "2      aparelho eficiente site marca aparelho impress...   \n",
       "3                            pouco travando valor ta boa   \n",
       "4      vendedor confiável produto ok entrega antes prazo   \n",
       "...                                                  ...   \n",
       "31469  entregou dentro prazo produto chegou condições...   \n",
       "31470  produto não enviado nf não existe venda nf cer...   \n",
       "31471  excelente mochila entrega super rápida super r...   \n",
       "31472  solicitei compra capa retrovisor celta prisma ...   \n",
       "31473  produto chegou ja devolver pois defeito não se...   \n",
       "\n",
       "                                            tratamento_2  \\\n",
       "0                      recebi bem antes prazo estipulado   \n",
       "1      parabens lojas zoop adorei comprar internet se...   \n",
       "2      aparelho eficiente site marca aparelho impress...   \n",
       "3                            pouco travando valor ta boa   \n",
       "4      vendedor confiavel produto ok entrega antes prazo   \n",
       "...                                                  ...   \n",
       "31469  entregou dentro prazo produto chegou condicoes...   \n",
       "31470  produto nao enviado nf nao existe venda nf cer...   \n",
       "31471  excelente mochila entrega super rapida super r...   \n",
       "31472  solicitei compra capa retrovisor celta prisma ...   \n",
       "31473  produto chegou ja devolver pois defeito nao se...   \n",
       "\n",
       "                                            tratamento_3  \\\n",
       "0                      recebi bem antes prazo estipulado   \n",
       "1      parabens lojas zop adorei comprar internet seg...   \n",
       "2      aparelho eficiente site marca aparelho impress...   \n",
       "3                            pouco travando valor ta boa   \n",
       "4      vendedor confiavel produto ok entrega antes prazo   \n",
       "...                                                  ...   \n",
       "31469  entregou dentro prazo produto chegou condicoes...   \n",
       "31470  produto nao enviado nf nao existe venda nf cer...   \n",
       "31471  excelente mochila entrega super rapida super r...   \n",
       "31472  solicitei compra capa retrovisor celta prisma ...   \n",
       "31473  produto chegou ja devolver pois defeito nao se...   \n",
       "\n",
       "                                            tratamento_4  \n",
       "0                      recebi bem antes prazo estipulado  \n",
       "1      parabem loja zop adorei comprar internet segur...  \n",
       "2      aparelho eficiente site marca aparelho imprimi...  \n",
       "3                              pouco travar valor to bom  \n",
       "4      vendedor confiavel produto ok entregar antes p...  \n",
       "...                                                  ...  \n",
       "31469  entregar dentro prazo produto chegar condico p...  \n",
       "31470  produto nao enviado em f nao existir venda em ...  \n",
       "31471  excelente mochila entregar super rapido super ...  \n",
       "31472  solicitei compra capa retrovisor celta prisma ...  \n",
       "31473  produto chegar ja devolver pois defeito nao se...  \n",
       "\n",
       "[31111 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lem = df.drop_duplicates(subset=['tratamento_4'])\n",
    "df_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ac427b42-d3a5-4adf-98c0-bed20e34eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lem.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07f3912a-95b3-4578-9908-575bf8619a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230614/1869549166.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lem['review_token'] = df_lem['tratamento_2'].apply(word_tokenize_pt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: preco entrega vale pena - Similaridade: 0.9167%\n",
      "Review: entrega prazo conforme anunciado - Similaridade: 0.9127%\n",
      "Review: entrega nota 10 - Similaridade: 0.8983%\n",
      "Review: entrega imediata satisfatoria - Similaridade: 0.8917%\n",
      "Review: prazo entrega dia 27 03 2018 hoje dia 29 03 2018 ainda nao recebi produto - Similaridade: 0.8891%\n"
     ]
    }
   ],
   "source": [
    "df_lem['review_token'] = df_lem['tratamento_2'].apply(word_tokenize_pt)\n",
    "dados_tag = [TaggedDocument(words=linha['review_token'], tags=[str(i)]) for i, linha in df_lem.iterrows()]\n",
    "modelo = Doc2Vec(dados_tag, vector_size=100, min_count=2, window=2, workers=1, seed=45, epochs=20)\n",
    "frases_similares = modelo.dv.most_similar([modelo.infer_vector(['entrega'])], topn=5)\n",
    "for idx, similaridade in frases_similares:\n",
    "    print(f\"Review: {df_lem.loc[int(idx), 'tratamento_2']} - Similaridade: {similaridade:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0e951-abaf-4792-b14d-4d48bcdf4da6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Melhorando o treinamento do Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37b0e85a-a071-4a27-81c2-11a92f4804c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = Doc2Vec(\n",
    "    vector_size=300,\n",
    "    min_count=2,\n",
    "    window=5,\n",
    "    workers=1,\n",
    "    seed=45,\n",
    "    epochs=15\n",
    ")\n",
    "modelo.build_vocab(dados_tag)\n",
    "modelo.train(\n",
    "    dados_tag,\n",
    "    total_examples=modelo.corpus_count,\n",
    "    epochs=modelo.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9310e51-3b48-477c-b348-ee17442922d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Verificando a similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5a196c4-bd25-41c7-aa47-42ddec98c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: entrega prazo melhor preço - Similaridade: 0.9192%\n",
      "Review: favor gostaria saber entrega - Similaridade: 0.9066%\n",
      "Review: otima compra entrega - Similaridade: 0.8972%\n",
      "Review: prazo entrega gigante assim conseguiram atrasar entrega - Similaridade: 0.8888%\n",
      "Review: produto chegou perfeitas condições entrega prazo - Similaridade: 0.8875%\n"
     ]
    }
   ],
   "source": [
    "frases_similares = modelo.dv.most_similar([modelo.infer_vector(['entrega'])], topn=5)\n",
    "for idx, similaridade in frases_similares:\n",
    "    print(f\"Review: {df_lem.loc[int(idx), 'tratamento_1']} - Similaridade: {similaridade:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ca519dd-b39a-4ec1-b384-7b0ff2ae7d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: produto devolvido vendedor - Similaridade: 0.9356%\n",
      "Review: vendedor pontualíssimo recomendo - Similaridade: 0.9293%\n",
      "Review: produto conforme descrito vendedor - Similaridade: 0.9255%\n",
      "Review: vendedor super - Similaridade: 0.9254%\n",
      "Review: exelente vendedor - Similaridade: 0.9219%\n"
     ]
    }
   ],
   "source": [
    "frases_similares = modelo.dv.most_similar([modelo.infer_vector(['vendedor'])], topn=5)\n",
    "for idx, similaridade in frases_similares:\n",
    "    print(f\"Review: {df_lem.loc[int(idx), 'tratamento_1']} - Similaridade: {similaridade:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a19ddae7-22ed-4acb-afb2-5177416636a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: objeto veio perfeita condições superou expectativas excelente produto obrigada - Similaridade: 0.1969%\n",
      "Review: bom atendimento recebi antes previsto chegou perfeitas condições - Similaridade: 0.1837%\n",
      "Review: inicio fiquei receio adorei rápido pratico obrigado - Similaridade: 0.1818%\n",
      "Review: bom fiquei medo observei entregue via correio sempre deixa entregar qualquer encomenda surpreendeu dia seguinte entregue - Similaridade: 0.1800%\n",
      "Review: excelente atendimento totalmente confiável - Similaridade: 0.1779%\n"
     ]
    }
   ],
   "source": [
    "frases_similares = modelo.dv.most_similar([modelo.infer_vector(['reputacao loja'])], topn=5)\n",
    "for idx, similaridade in frases_similares:\n",
    "    print(f\"Review: {df_lem.loc[int(idx), 'tratamento_1']} - Similaridade: {similaridade:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a689d-9ca4-4657-97be-ad4766b1efc3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: entendendo os vetores e a similaridade\n",
    "\n",
    "O Doc2Vec, modelo que utilizamos até agora no nosso projeto, gera vetores dos textos, o que também chamamos de embeddings. Embeddings são representações numéricas de palavras ou frases em um espaço vetorial multidimensional, permitindo que computadores compreendam relações semânticas de maneira eficaz.\n",
    "\n",
    "Diferente da tokenização, que converte o texto em unidades menores (tokens) e os mapeia para índices numéricos fixos, os embeddings atribuem coordenadas a esses tokens, posicionando-os em um espaço vetorial de forma que elementos semanticamente similares fiquem próximos.\n",
    "\n",
    "A construção dos embeddings pelo Doc2Vec se dá através de um processo de treinamento que envolve contextos de palavras e o próprio documento. Existem duas abordagens principais no Doc2Vec: PV-FM (Distributed Memory) e PV-DBOW (Distributed Bag of Words). Ambas a abordagens treinam um modelo para prever palavras com base em contextos e também para associar cada documento a um vetor que reflete seu conteúdo geral.\n",
    "\n",
    "No final, esses vetores se tornam embeddings que representam semanticamente o documento completo em um espaço multidimensional, de forma que a proximidade entre eles reflete sua similaridade de significado. Por exemplo, textos como “*meu cachorro*” e “*meu gato fofo*” podem ser colocados perto um do outro, pois ambos se referem a animais de estimação, enquanto uma frase como “*eu fui ao banco*” estaria mais distante, indicando um contexto diferente.\n",
    "\n",
    "A similaridade entre esses vetores é medida com técnicas como a **distância euclidiana** ou a **similaridade de cosseno**. Essas medidas indicam quão próximas ou distantes duas palavras estão no espaço vetorial, refletindo sua semelhança semântica.\n",
    "\n",
    "A Norma L2, também conhecida como **Distância Euclidiana**, é uma medida matemática amplamente usada para calcular a distância entre dois pontos em um espaço vetorial. Na prática, ela mede o “caminho mais curto” entre dois vetores, o que faz dela uma escolha comum para avaliar similaridades em tarefas de machine learning e NLP.\n",
    "\n",
    "A distância entre dois pontos no plano pode ser calculada pela fórmula da hipotenusa, uma aplicação direta do [Teorema de Pitágoras](https://pt.wikipedia.org/wiki/Teorema_de_Pit%C3%A1goras) como mostrado na figura abaixo:\n",
    "\n",
    "![Distância Euclidiana](https://cdn3.gnarususercontent.com.br/3973-nlp/Imagens%20das%20atividades/Distancia%20euclidiana.png)\n",
    "\n",
    "A mesma lógica pode ser estendida a espaços de dimensões superiores, como aqueles utilizados em embeddings de palavras ou documentos. Por exemplo, se temos dois vetores de embeddings em um espaço multidimensional, a fórmula continua se aplicando, calculando a raiz quadrada da soma dos quadrados das diferenças entre cada componente dos vetores.\n",
    "\n",
    "Essa medida vai representar de forma intuitiva a proximidade entre pontos: quanto menor a distância, mais próximos os vetores estão e, por consequência, mais similares são os elementos que eles representam. No caso de embeddings, isso significa que palavras ou documentos com significados semelhantes terão valores que estarão mais próximos uns dos outros no espaço vetorial.\n",
    "\n",
    "A **similaridade do cosseno**, ou **distância cosseno**, é uma medida amplamente utilizada em processamento de linguagem natural (NLP) para avaliar o grau de semelhança entre dois vetores. Ao contrário de outras medidas como a distância euclidiana, a similaridade do cosseno foca apenas na direção dos vetores, ignorando a magnitude. Isso significa que ela funciona para comparar textos em que o conteúdo é importante, mas o comprimento das frases pode variar.\n",
    "\n",
    "A similaridade do cosseno é definida pelo cosseno do ângulo entre dois vetores no espaço vetorial. Se o ângulo entre os vetores é zero, isso significa que eles apontam na mesma direção e são completamente semelhantes, com a similaridade de cosseno sendo igual a 1 (máxima similaridade). Por outro lado, se os vetores forem ortogonais, ou seja, se formarem um ângulo de 90 graus, a similaridade será 0, indicando que não possuem relação semântica. Ângulos maiores, como 180° geram um resultado negativo, sendo ele igual a 1, indicando vetores opostos.\n",
    "\n",
    "![Similaridade cosseno](https://cdn3.gnarususercontent.com.br/3973-nlp/Imagens%20das%20atividades/Similaridade%20cosseno.png)\n",
    "\n",
    "> Para se aprofundar no uso prático da similaridade de cosseno em NLP, você pode explorar [esta demonstração sobre embeddings e similaridades no Gensim](https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html) e verificar exemplos práticos de implementação na [documentação do scikit-learn](https://scikit-learn.org/stable/modules/metrics.html#cosine-similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6214103b-3e55-4762-9964-bab3450ba427",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 04. Considerando o significado das frases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5135152-1c94-457a-bf8b-5e5435645731",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Utilizando um modelo mais robusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec2874e4-08b7-4d83-837c-1f6f568d3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "modulo_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d599540a-4d48-4aae-b24f-54b810afdda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 09:29:32.246626: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-21 09:29:32.374491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-21 09:29:32.425431: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-21 09:29:32.439325: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-21 09:29:32.533170: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-21 09:29:33.332395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-21 09:30:04.804063: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "modelo = hub.load(modulo_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89fecedb-dbb4-4051-84fa-20116c980b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject at 0x75a63bbb82f0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "048a4ae9-d85e-4ce4-ada3-5092ec55d94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 09:30:07.854168: E tensorflow/core/util/util.cc:131] oneDNN supports DT_INT64 only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(31474, 512), dtype=float32, numpy=\n",
       "array([[ 0.0477517 ,  0.01094662, -0.05415082, ...,  0.0907801 ,\n",
       "        -0.02599914, -0.09261212],\n",
       "       [-0.00746652, -0.06605156, -0.04505714, ...,  0.05561578,\n",
       "        -0.02624756, -0.07801282],\n",
       "       [-0.00820427,  0.04282851, -0.02907444, ...,  0.07496072,\n",
       "        -0.06071885, -0.07618524],\n",
       "       ...,\n",
       "       [ 0.02074313, -0.05436159, -0.06415591, ...,  0.07194226,\n",
       "         0.01059286, -0.07603392],\n",
       "       [-0.04131036, -0.03054745,  0.01322935, ...,  0.06785525,\n",
       "        -0.0252889 , -0.07106064],\n",
       "       [ 0.05717908, -0.05808826, -0.02038887, ...,  0.07339787,\n",
       "        -0.06409647, -0.08014238]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = df['tratamento_3'].tolist()\n",
    "reviews_emb = modelo(reviews)\n",
    "reviews_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eed621f7-f276-4641-b83f-5cf50aaf46cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000002 , 0.6158628 , 0.5175547 , ..., 0.54277545, 0.57541025,\n",
       "        0.6691027 ],\n",
       "       [0.6158628 , 1.0000001 , 0.5666107 , ..., 0.63920605, 0.6011834 ,\n",
       "        0.67117447],\n",
       "       [0.5175547 , 0.5666107 , 0.99999964, ..., 0.58997357, 0.6564975 ,\n",
       "        0.59229845],\n",
       "       ...,\n",
       "       [0.54277545, 0.63920605, 0.58997357, ..., 0.9999999 , 0.6378721 ,\n",
       "        0.61628103],\n",
       "       [0.57541025, 0.6011834 , 0.6564975 , ..., 0.6378721 , 1.0000002 ,\n",
       "        0.6389235 ],\n",
       "       [0.6691027 , 0.67117447, 0.59229845, ..., 0.61628103, 0.6389235 ,\n",
       "        1.0000001 ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(reviews_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46649969-ffa8-46b9-b4f5-5bde7048203b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: o que é o Universal Sentence Encoder (USE)\n",
    "\n",
    "O **Universal Sentence Encoder (USE)** é uma ferramenta desenvolvida pelo Google que gera embeddings de sentenças, ou seja, representações numéricas de frases em um espaço vetorial. Diferente dos embeddings de palavras tradicionais, como o Word2Vec, o USE cria vetores para sentenças completas, facilitando a captura do contexto e do significado da frase como um todo, o que se torna muito útil para tarefas que exigem a compreensão do sentido geral de um texto.\n",
    "\n",
    "Para construir esses embeddings, o USE oferece duas arquiteturas:\n",
    "- uma baseada em **Transformers** e\n",
    "- outra em **Deep Averaging Network (DAN)**.\n",
    "\n",
    "A aquitetura de Transformers é mais complexa e precisa, utilizando o mecanismo de atenção para capturar as relações entre palavras, levando em consideração tanto a ordem quanto o contexto das palavras em uma sentença. Já a arquitetura DAN, embora mais simples, utiliza uma média das palavras e bigramas para gerar o embedding, sendo mais ráṕida e eficiente em termos de computação. Ambas as abordagens produzem embeddings de tamanho fixo, com 512 dimensões, o que facilita o uso dos vetores para comparar sentenças de diferentes comprimentos.\n",
    "\n",
    "Esses embeddings têm uma propriedade importante: ao converter frases em vetores no mesmo espaço vetorial, o USE permite que sentenças com significados parecidos fiquem próximas umas das outras. Por exemplo, frases como “eu gosto de maçãs” e “eu adoro frutas” terão vetores relativamente próximos, pois compartilham um contexto semelhante relacionado à apreciação de alimentos. Esse cálculo de similaridade pode ser feito facilmente usando medidas como a **similaridade de cosseno**.\n",
    "\n",
    "> Consulte o artigo [*Universal Sentence Encoder*](https://static.googleusercontent.com/media/research.google.com/pt-BR//pubs/archive/46808.pdf) para entender de forma mais profunda e detalhada sobre o USE.\n",
    "\n",
    "O Universal Sentece Encoder é disponibilizado gratuitamente no [TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4), onde devs podem integrá-lo a sistemas de NLP para tarefas como análise de sentimentos, classificação de texto e busca de similaridade semântica. A simplicidade de implementação permite que ele seja amplamente utilizado para resolver problemas de similaridade entre sentenças, classificação e outras aplicações que dependem da compreensão do contexto e da semântica de frases completas.\n",
    "\n",
    "Para experimentar o USE em suas aplicações, consulte a [documentação do TensorFlow Hub](https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder?hl=pt-br) e acesse tutoriais e exemplos práticos no [GitHub do TensorFlow](https://github.com/tensorflow/docs/tree/master/site/en/hub/tutorials)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e023a-f6c7-46b8-afef-dd0d1c2d4505",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Avaliando a similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "349200a1-a42c-4044-a757-b4a9e3b5b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sentencas_similares(tema, reviews, reviews_emb, top_n=5):\n",
    "    tema_emb = modelo([tema])\n",
    "    similaridades = cosine_similarity(tema_emb, reviews_emb).flatten()\n",
    "    indices_similaridades = np.argsort(-similaridades)\n",
    "    for idx in indices_similaridades[:top_n]:\n",
    "        print(f\"Review: {reviews[idx]} - Similaridade: {similaridades[idx]:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ed8c919-b459-48fb-8166-a8e0d46201cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: eficiente entrega - Similaridade: 0.6829%\n",
      "Review: entrega eficiente - Similaridade: 0.6756%\n",
      "Review: agil entrega - Similaridade: 0.6563%\n",
      "Review: entrega prazo - Similaridade: 0.6473%\n",
      "Review: entrega agil - Similaridade: 0.6471%\n"
     ]
    }
   ],
   "source": [
    "sentencas_similares('entrega', reviews, reviews_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b40dab4-9750-42b1-9e6d-64a94abe3bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: otima loja - Similaridade: 0.8578%\n",
      "Review: recomento loja - Similaridade: 0.8339%\n",
      "Review: pessima loja - Similaridade: 0.8335%\n",
      "Review: adorei loja - Similaridade: 0.8170%\n",
      "Review: rapidez eficiencia loja - Similaridade: 0.8018%\n",
      "Review: loja confianca - Similaridade: 0.7909%\n",
      "Review: produto loja confianca - Similaridade: 0.7888%\n",
      "Review: loja ruim - Similaridade: 0.7868%\n",
      "Review: otimas experiencias loja - Similaridade: 0.7839%\n",
      "Review: satisfeita produto loja - Similaridade: 0.7816%\n"
     ]
    }
   ],
   "source": [
    "sentencas_similares('reputação loja', reviews, reviews_emb, top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb834b4-c6de-4539-8603-8c2d97da1f26",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 05. Transformando a similaridade em aplicação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481f9d3-6805-4971-ad96-dcd9c7a74142",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Iniciando a construção da aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1ec75a4-d1a7-47f1-b078-0d53e5ebf84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/cristoffer_pogan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/cristoffer_pogan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "modulo_url = 'https://tfhub.dev/google/universal-sentence-encoder/4'\n",
    "modelo = hub.load(modulo_url)\n",
    "\n",
    "def tratar_texto(texto):\n",
    "    texto = re.sub(r'\\W', ' ', texto.lower())\n",
    "\n",
    "    word_tokenize_pt = partial(word_tokenize, language='portuguese')\n",
    "    tokens = word_tokenize_pt(texto)\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    stop_words.discard('não')\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    texto_sem_acentos = unidecode(' '.join(tokens))\n",
    "\n",
    "    texto_normalizado = re.sub(r'(?!rr|ss)(.)\\1+', r'\\1', texto_sem_acentos)\n",
    "    return texto_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12fcd024-3cde-4ed1-85a1-521ad9da6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dados_teste = pd.read_csv(url)\n",
    "# dados_teste['review'].apply(tratar_texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa640d-9d56-485b-bf7c-57861118351e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Finalizando os passos da aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d12de271-50ba-4b27-872d-bc291ebbfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(arquivo, tema):\n",
    "    df = pd.read_csv(arquivo.name)\n",
    "\n",
    "    df['review_tratada'] = df['review'].apply(tratar_texto)\n",
    "    df = df[df['review_tratada'] != '']\n",
    "    df.drop_duplicates(subset=['review_tratada'], inplace=True)\n",
    "\n",
    "    reviews_emb = modelo(df['review_tratada'].tolist())\n",
    "    tema_emb = modelo([tema])\n",
    "\n",
    "    similaridades = cosine_similarity(tema_emb, reviews_emb).flatten()\n",
    "    top_indices = np.argsort(-similaridades)\n",
    "\n",
    "    similar_reviews = df[['nota_review', 'review']].iloc[top_indices]\n",
    "\n",
    "    similar_df = similar_reviews.head(200)\n",
    "\n",
    "    nome_arquivo = f\"reviews_similares_{tema}.csv\"\n",
    "    similar_reviews.to_csv(nome_arquivo)\n",
    "    return similar_df, nome_arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "434cf3f6-377f-427f-aa61-0662728c5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_csv(url, 'entrega')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3e6475-1b97-44e8-aeb5-66e4cab841fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Utilizando o Gradio para executar a aplicação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d0a1d8b-ac90-4e79-ba5a-66f479ce33ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd66435-a937-4f06-b158-6d36ab2b4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as app:\n",
    "    with gr.Row():\n",
    "        gr.Markdown('## Encontrando as reviews mais similares ao tema')\n",
    "    csv_entrada = gr.File(label='Envie o CSV com as reviews', file_types=['.csv'])\n",
    "    tema_entrada = gr.Textbox(label='Digite o tema para busca (ex: “entrega”)')\n",
    "\n",
    "    botao = gr.Button('Clique aqui para buscar as reviews')\n",
    "\n",
    "    tabela_saida = gr.Dataframe(label='Top 200 reviews similares', headers=['Nota', 'Reviews'], interactive=False)\n",
    "    arquivo_saida = gr.File(label='Baixar CSV ordenado com as reviews mais similares ao tema', interactive=False)\n",
    "\n",
    "    botao.click(fn=process_csv, inputs=[csv_entrada, tema_entrada], outputs=[tabela_saida, arquivo_saida])\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7576b1-a7b6-415a-b5a0-5a721d65eec6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: o que é o Gradio\n",
    "\n",
    "O Gradio é um pacote de código aberto em Python que permite criar rapidamente uma demonstração ou aplicação web para modelos de machine learning, APIs ou qualquer função em Python. Com ele, é possível compartilhar um link para a demonstração ou aplicação web em questão de segundos, utilizando os recursos integrados de compartilhamento do Gradio. Além disso, não é necessário ter conhecimento em JavaScript, CSS ou experiência em hospedagem web.\n",
    "\n",
    "> Você pode acessar informações sobre o Gradio, documentação e tutoriais nesse [link](https://www.gradio.app/).\n",
    "\n",
    "Com ele podemos publicar diversas aplicações desenvolvidas em Python na web para que várias pessoas possam acessar. Por conta disso, o Gradio é uma ótima ferramenta para compartilhar o que foi criado durante as aulas e disponibilizar para as pessoas interessadas ou mesmo divulgar o trabalho que você desenvolveu em seus estudos como seu portfólio!\n",
    "\n",
    "Para utilizar o Gradio no Google Colab é preciso fazer a instalação do pacote no ambiente, pois o Gradio não é uma biblioteca nativa do Colab.\n",
    "\n",
    "```bash\n",
    "!pip install gradio\n",
    "```\n",
    "\n",
    "Para entender como utilizar o Gradio, vamos construir uma interface simples!\n",
    "\n",
    "> Acesse o código completo deste tutorial nesse [notebook Colab](https://cdn3.gnarususercontent.com.br/3973-nlp/Projeto/Demo-Gradio.ipynb) ou no [GitHub](https://github.com/Mirlaa/NLP-trabalhando-similaridade-sentencas/blob/3a1b8378aa2151e392d1cb0bd0c5de2feeca8722/Demo_Gradio.ipynb).\n",
    "\n",
    "A aplicação busca receber o nome das duas primeiras colunas desejadas para um DataFrame pré-definido. Assim que o botão é clicado, a aplicação renomeia as colunas conforme especificado, exibe o dataframe com as novas colunas e permite o download em formato JSON.\n",
    "\n",
    "#### Passo 1: Importar bibliotecas necessárias\n",
    "\n",
    "Importando o Gradio e o Pandas, que usaremos para manipular o DataFrame. O Gradio permite criar interfaces visuais para funções Python de maneira simples e rápida.\n",
    "\n",
    "```python\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "#### Passo 2: Definir o DataFrame\n",
    "\n",
    "Para simplificar, definimos um DataFrame básico com duas colunas chamadas `Coluna1` e `Coluna2`. Esse DataFrame será utilizado na demonstração.\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'Coluna1': ['A', 'B', 'C'],\n",
    "    'Coluna2': [1, 2, 3]\n",
    "})\n",
    "```\n",
    "\n",
    "#### Passo 3: Função para renomear coluna\n",
    "\n",
    "Definimos a função `renomear_coluna`, que renomeia as duas primeiras colunas do DataFrame de acordo com os nomes fornecidos pelo usuário. Ela também converte o DataFrame atualizado em formato JSON para que a pessoa que usa a aplicação possa baixá-lo.\n",
    "\n",
    "```python\n",
    "def renomear_coluna(col1_name, col2_name):\n",
    "  # Renomear as colunas\n",
    "  df_renomeado = df.copy()\n",
    "  df_renomeado.columns = [col1_name, col2_name]\n",
    "\n",
    "  # Converter para JSON\n",
    "  nome_arquivo = f'df_renomeado.json'\n",
    "  df_renomeado.to_json(nome_arquivo, orient='records')\n",
    "  return df_renomeado, nome_arquivo\n",
    "```\n",
    "\n",
    "A função `renomear_coluna` recebe dois argumentos: `col1_name` e `col2_name`, que são os novos nomes para as duas primeiras colunas. Em seguida, ela cria uma cópia do DataFrame original e renomeia suas colunas. A função então converte o DataFrame renomeado em formato JSON e retorna tanto o DataFrame quanto o caminho para o arquivo JSON.\n",
    "\n",
    "> *Até aqui não usamos o Gradio, apenas constuímos a essência da nossa aplicação: renomeas colunas do DataFrame e criar um arquivo JSON*.\n",
    "\n",
    "#### Passo 4: Interface Gradio\n",
    "\n",
    "Agora construímos nossa interface no Gradio. Começamos **estruturando a interface**:\n",
    "\n",
    "1. `with gr.Block() as app:`\n",
    "    - `gr.Blocks()`cria um **contêiner** para a interface, onde podemos organizar visualmente os componentes em uma estutura hierárquica.\n",
    "    - `as app:` armazena a interface em uma variável (`app`), que podemos usar para lançar a aplicação mais tarde com `app.launch()`.\n",
    "\n",
    "2. `gr.Markdown()`\n",
    "    - Exibe texto formatado usando a linguagem Markdown. Nesse caso, é usado para exibir o título “Renomeie as colunas do DataFrame”.\n",
    "    - `gr.Markdown(\"Renomeie as colunas do DataFrame\")`: `##` no Markdown cria um cabeçalho de segundo nível. É uma maneira simples de adicionar textos explicativos ou títulos à interface.\n",
    "\n",
    "```python\n",
    "with gr.Blocks() as app:\n",
    "  gr.Markdown('## Renomeie as colunas do DataFrame')\n",
    "```\n",
    "\n",
    "Com a interface estruturada sequimos para a definição das **entradas** que a pessoa que usar a aplicação irá definir com `gr.Textbox()`:\n",
    "\n",
    "3. `gr.Textbox()`\n",
    "    - Cria uma **caixa de texto** onde o usuário pode inserir indormações.\n",
    "    - `label=\"Nome da primeira coluna\"`: Define o rótulo exibido ao lado da caixa de texto. No caso, “Nome da primeira coluna” ajuda o usuário a entender o que deve inserir.\n",
    "    - `col1_entrada = gr.Textbox(label=\"Nome da primeira coluna\")`: Aqui, criamos um campo onde o usuário insere o nome da primeira coluna. O segundo campo (`col2_entrada`) é para o nome da segunda coluna.\n",
    "\n",
    "```python\n",
    "with gr.Blocks() as app:\n",
    "  gr.Markdown('## Renomeie as colunas do DataFrame')\n",
    "  # Entradas\n",
    "  col1_entrada = gr.Textbox(label='Nome da primeira coluna')\n",
    "  col2_entrada = gr.Textbox(label='Nome da segunda coluna')\n",
    "```\n",
    "\n",
    "4. `gr.Button()`\n",
    "    - Cria um botão interativo que, quando clicado, pode acionar uma função específica.\n",
    "    - `gr.Button(\"Renomear Colunas\")`: O parâmetro `\"Renomear Colunas\"` define o texto exibido no botão. Quando o botão é clicado, ele dispara uma função configurada com o método `.click()`.\n",
    "\n",
    "```python\n",
    "with gr.Blocks() as app:\n",
    "  gr.Markdown('## Renomeie as colunas do DataFrame')\n",
    "  # Entradas\n",
    "  col1_entrada = gr.Textbox(label='Nome da primeira coluna')\n",
    "  col2_entrada = gr.Textbox(label='Nome da segunda coluna')\n",
    "  #Botão\n",
    "  botao = gr.Button('Renomear Colunas')\n",
    "```\n",
    "\n",
    "Agora, definimos as saídas: uma visualização do dataframe renomeado e a opção de baixar o arquivo JSON da tabela renomeada.\n",
    "\n",
    "5. `gr.Dataframe()`\n",
    "   - Exibe um DataFrame na interface, permitindo que o usuário visualize os dados.\n",
    "   - `label=\"DataFrame com colunas renomeadas\"`: Define o rótulo exibido acima da tabela.\n",
    "   - `interactive=False`: Define se o usuário pode interagir com o DataFrame exibido (como editar células). Aqui, `False` impede a interação direta do usuário com os dados exibidos.\n",
    "\n",
    "6. `gr.File()`\n",
    "   - Permite que o usuário baixe ou envie arquivos.\n",
    "   - `label=\"Baixar JSON do DataFrame\"`: Define o rótulo exibido para o componente de download.\n",
    "   - `interactive=False`: Define que o usuário não pode modificar diretamente esse componente na interface. Aqui, ele só permite o download do arquivo JSON gerado.\n",
    "\n",
    "```python\n",
    "with gr.Block() as app:\n",
    "    gr.Markdown('## Renomeie as colunas do DataFrame')\n",
    "    # Entradas\n",
    "    col1_entrada = gr.Textbox(label='Nome da primeira coluna')\n",
    "    col2_entrada = gr.Textbox(label='Nome da segunda coluna')\n",
    "    # Botão\n",
    "    botao = gr.Button('Renomear colunas')\n",
    "    # Saídas\n",
    "    tabela_saida = gr.Dataframe(label='DataFrame com colunas renomeadas', interactive=False)\n",
    "    arquivo_saida = gr.File(label='Baixar JSON do DataFrame', interactive=False)\n",
    "```\n",
    "\n",
    "Por fim, definimos a ação que vai ocorrer a partir do momento que uma pessoa clicar no botão.\n",
    "\n",
    "7. `botao.click()`\n",
    "   - Configura a ação que ocorre ao clicar no botão.\n",
    "   - **Parâmetros**:\n",
    "     - `fn=rename_columns`: A função que será executada ao clicar no botão. Neste caso, a função `rename_columns` renomeia as colunas do DataFrame e converte o resultado para JSON.\n",
    "     - `inputs=[col1_entrada, col2_entrada]`: Lista de entradas que a função `rename_columns` recebe. Aqui, são os valores dos campos `col1_entrada` e `col2_entrada` (novos nomes das colunas).\n",
    "     - `outputs=[tabela_saida, arquivo_saida]`: Lista dos componentes de saída onde os resultados da função serão exibidos. Aqui, o `DataFrame` renomeado é exibido em `tabela_saida` e o JSON gerado é disponibilizado para download em `arquivo_saida`.\n",
    "\n",
    "O código final do bloco da interface pode ser verificado abaixo:\n",
    "\n",
    "```python\n",
    "with gr.Blocks() as app:\n",
    "  gr.Markdown('## Renomeie as colunas do DataFrame')\n",
    "  # Entradas\n",
    "  col1_entrada = gr.Textbox(label='Nome da primeira coluna')\n",
    "  col2_entrada = gr.Textbox(label='Nome da segunda coluna')\n",
    "  #Botão\n",
    "  botao = gr.Button('Renomear Colunas')\n",
    "  # Saídas\n",
    "  tabela_saida = gr.Dataframe(label='DataFrame com colunas renomeadas', interactive=False)\n",
    "  arquivo_saida = gr.File(label='Baixar JSON do DataFrame', interactive=False)\n",
    "\n",
    "  # Definindo o que acontece ao clicar no botão\n",
    "  botao.click(\n",
    "    renomear_coluna,\n",
    "    inputs=[col1_entrada, col2_entrada],\n",
    "    outputs=[tabela_saida, arquivo_saida]\n",
    "  )\n",
    "```\n",
    "\n",
    "#### Passo 5: Iniciando a interface\n",
    "\n",
    "Para terminar construção da aplicação, chamamos `app.launch()` para iniciar a aplicação e gerar a interface interativa.\n",
    "\n",
    "```python\n",
    "app.lauch()\n",
    "```\n",
    "\n",
    "#### Resultado\n",
    "\n",
    "Obtemos acesso a interface do Gradio que podemos rodar diretamente no notebook Colab. Você pode observar o uso final da aplicação no gif abaixo:\n",
    "\n",
    "![app](https://cdn3.gnarususercontent.com.br/3973-nlp/Imagens%20das%20atividades/demo-gradio.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b37b6-9b99-4f03-bf86-ee3c45f0267f",
   "metadata": {},
   "source": [
    "## Para ir mais a fundo\n",
    "\n",
    "[Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781)\n",
    "\n",
    "[Distibuted Representations of Sentences and Documents](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)\n",
    "\n",
    "[Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)\n",
    "\n",
    "[Stanza: A Python Natural Language Processing Toolkit for Many Human Languages](https://arxiv.org/abs/2003.07082)\n",
    "\n",
    "[Gradio Documentation](https://www.gradio.app/docs)\n",
    "\n",
    "[Gensim Documentation](https://radimrehurek.com/gensim/auto_examples/index.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Similaridade de Sentenças (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

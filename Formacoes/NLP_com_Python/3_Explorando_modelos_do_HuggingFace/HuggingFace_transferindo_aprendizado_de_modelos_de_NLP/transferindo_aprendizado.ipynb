{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394ad28a-f433-45d1-9ff7-6163871ecad0",
   "metadata": {},
   "source": [
    "# Hugging Face: transferindo aprendizado de modelos de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff1204-b13b-4bd5-b435-94a1a865d802",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 01. Explorando o modelo pré-treinado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1c85d-6070-4f40-8929-ff68d3e4b22c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Utilizando o Hugging Face pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25705072-7c26-4b67-9503-7440f224835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e513ff-70f5-422e-8942-716d7524b607",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = pipeline('zero-shot-classification', model='Mel-Iza0/zero-shot', tokenizer='Mel-Iza0/zero-shot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b22891-b89f-46a1-8d16-408c84df4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"\n",
    "Com o início da era digital, a capacidade de transmissão de informações cresceu apressuradamente, \n",
    "o que facilitou o contato com diversos assuntos, dentre eles a educação sexual . \n",
    "Entretanto, surgiram paralelamente algumas questões, das quais se destacam a preocupação \n",
    "com o momento adequado do ingresso do tema a vida do estudante, assim como de maneira antagônica, \n",
    "o aumento de casos de DST´S\\\\xa0\\\\xa0e gravidez indesejada nesse período, a qual leva a um maior \n",
    "questionamento sobre o começo desta pauta., A falta de comunicação sobre a sexualidade \n",
    "entre jovens no Brasil acarreta muitas das vezes\\\\xa0na inserção desses em um meio \n",
    "repleto de dúvidas, gerando a ocorrência de doenças sexualmente transmissíveis e de gravidez precoce. \n",
    "Com base nisso, muitos adolescentes buscam compreender melhor essas questões na internet, \n",
    "local onde se podem encontrar notícias falsas ou inadequadas para seu desenvolvimento, \n",
    "impedindo assim a correta compreensão do assunto, assim como a responsabilidade imposta por ele.\n",
    ", Por outro lado, o diálogo em relação à sexualidade e seus tópicos é um tabu para pais e professores, \n",
    "que se sentem desorientados sobre a devida hora e os devidos critérios a serem tratados \n",
    "com os filhos e alunos, dificultando com que esses esclareçam suas dúvidas e entenda de maneira correta, \n",
    "o que levaria a conscientização da seriedade dessa discussão., Em virtude do que foi mencionado, \n",
    "as indagações a respeito divide várias opiniões e reflexões acima do que deve ser feito. \n",
    "É de extrema importância o Ministério da Educação, em parceria com o Ministério da Cidadania, \n",
    "implantar a educação sexual na matriz curricular estudantil dos jovens, através de aulas elaboradas \n",
    "e destinadas ao esclarecimento de perguntas, assim como palestras e programas com a intenção de \n",
    "propagar o conteúdo aos estudantes, contando com o suporte dos pais, funcionários e encarregados \n",
    "da rede de ensino no país, para que seja realizado constantemente.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e839c5a-d4f7-4d69-a294-2cc7f8a24dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador(texto, candidate_labels=[str(i) for i in range(11)])['labels'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab591be-d390-4a20-aff2-8765c8f15b94",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: aprendizado Zero-Shot\n",
    "\n",
    "Normalmente, modelos de IA que classificam dados em categorias são treinados de forma supervisionada, utilizando uma base de dados que contém os rótulos a serem previstos. Esses modelos supervisionados se tornam especialistas em uma tarefa específica, mas, quando surge um novo rótulo, eles não sabem como classificá-lo. Nesse caso, seria necessário treinar um novo modelo do zero, incorporando o novo rótulo na variável alvo.\n",
    "\n",
    "#### Alternativa aos modelos convencionais\n",
    "\n",
    "Uma alternativa promissora para contornar essa limitação é o Zero-Shot Learning (Aprendizado Zero-Shot). Este tipo de aprendizado permite que modelos de IA reconheçam e classifiquem novos rótulos que não estavam presentes durante o treinamento inicial. Isso é possível graças ao uso de descrições ou atributos dos novos rótulos, que são aprendidos de maneira a permitir que o modelo generalize para categorias inéditas.\n",
    "\n",
    "No aprendizado Zero-Shot, os modelos são treinados com uma combinação de dados rotulados e metadados que descrevem os rótulos. Por exemplo, em uma tarefa de classificação de imagens, o modelo pode ser treinado não apenas com imagens de gatos e cavalos, mas também com descrições textuais dessas classes. Assim, quando o modelo se depara com uma nova classe, como “tigre”, ele pode usar o conhecimento das descrições textuais para inferir as características do tigre, mesmo sem ter visto imagens dessa classe durante o treinamento.\n",
    "\n",
    "![Aprendizado Zero-Shot](http://cdn3.gnarususercontent.com.br/3977-hugging-face/Imagens%20das%20atividades/ZERO%20SHOT.png)\n",
    "\n",
    "Essa abordagem é particularmente útil em domínios onde é impraticável ou impossível obter exemplos rotulados para todas as categorias possíveis. Em áreas como diagnóstico médico, reconhecimento de objetos ou processamento de linguagem natural, novas classes de dados podem surgir frequentemente, e o Zero-Shot oferece uma maneira eficiente de lidar com essas situações sem a necessidade de re-treinar modelos extensivamente.\n",
    "\n",
    "Além disso, o Aprendizado Zero-Shot pode ser complementado com técnicas como o Few-Shot Learning, onde o modelo é adaptado para aprender novas classes com um número muito pequeno de exemplos rotulados. Juntas, essas abordagens ampliam a capacidade dos modelos de IA de se adaptarem a novos desafios, tornando-os mais flexíveis e robustos em ambientes dinâmicos e em constante mudança.\n",
    "\n",
    "Um grande desafio enfrentado na utilização deste tipo de aprendizado está na dificuldade em lidar com a variabilidade que pode ocorrer dos conceitos que não foram vistos durante o treinamento. Como o modelo não teve contato com exemplos desses conceitos, ele pode ter dificuldades em fazer previsões precisas.\n",
    "\n",
    "Em resumo, o Zero-Shot Learning constitui um avanço importante no campo da inteligência artificial, permitindo que modelos identifiquem e classifiquem novas categorias sem depender de grandes quantidades de dados rotulados. Essa habilidade de generalização é essencial para criar sistemas de IA mais versáteis e escaláveis, capazes de lidar com a diversidade e a complexidade do mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74e41a3-d438-4989-aa61-d1598e41356b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Realizando o deploy com o Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df169e-7df3-417e-9e9c-85f13a9ecac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import gradio as gr\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec94db-8132-40cf-8080-a2e7803db419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_resultado(texto: str) -> dict[str, Any]:\n",
    "    return classificador(texto, candidate_labels=[str(i) for i in range(11)])['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfefb7e0-4dcb-409b-94bd-d27ddc63226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app = gr.Interface(\n",
    "#     fn=mostrar_resultado,\n",
    "#     inputs=['text'],\n",
    "#     outputs=['text']\n",
    "# )\n",
    "# app.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7d331-baf7-4c98-b9d0-a999dfc3bfbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 02. Preparando dados de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0ce25f-e925-432e-8712-c2dd42ad1cbe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Carregando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2090e116-27ed-4ad1-a056-c81083738a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7f6381-514c-46a5-86c8-0ecce67743f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes = load_dataset('csv', data_files='./redacoes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a90d307-072f-439d-8ee7-16f0e5fb1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631ad9a-61b5-4b6c-b30b-785da7901bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde9d21-f44f-40c3-9b99-a56f59a7b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes['train']['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bf985-ce72-46ab-9d8b-00e9b235e7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes['train']['score'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11cf69-81f9-466a-bde0-24c1cd583f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01cc22-6630-4b45-8ea8-8576ee71a6eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Separando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ece6f-af22-4424-b9f0-7a8d25ed61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "treino_teste = dados_redacoes['train'].train_test_split(test_size=0.2, shuffle=False)\n",
    "treino_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e14ab67-2943-4bc9-a5cc-f4e041d1874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77f2a0-e46a-4a36-9193-0b7e3be847a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes = DatasetDict({\n",
    "    'treino': treino_teste['train'],\n",
    "    'teste': treino_teste['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed4cb6b-66b5-4fe4-acd1-74d2ffd2e665",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75e3c70-c20e-4730-9418-90547dba10f6",
   "metadata": {},
   "source": [
    "[Datasets - Hugging Face](https://huggingface.co/datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1652c7-d258-45cb-951f-f7c516425530",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenizando dados textuais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c7d82-4c28-422e-9652-ab95c9fad3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_modelo = 'Geotrend/distilbert-base-pt-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed75e1-30e8-4976-ab3a-a7e9f8ba405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4167628-b80c-45fb-b888-1b6b3eb5f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizador = AutoTokenizer.from_pretrained(checkpoint_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf222e-a555-4ba8-8a61-fd1b0ec9e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = dados_redacoes['treino']['essay'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0b410-2ec5-4800-a93a-ff0c22557026",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizador.tokenize(texto)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f90e78-7af9-4060-b694-726f497173d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizador.convert_tokens_to_ids(tokens)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54356e34-499b-4539-a038-762c5e5cb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_decodificado = tokenizador.decode(ids)\n",
    "print(texto_decodificado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25cdf97-749e-4727-96f7-e53f1a58e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_codificado = tokenizador(texto, return_tensors='tf')\n",
    "print(input_codificado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41039448-efbd-49b0-ac37-109359ee0341",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tokenizando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6b843-b1da-42d1-9a80-8e058e6e3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcao_tokenizadora(dados_texto):\n",
    "    return tokenizador(dados_texto['essay'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb025f5-455c-4a3b-a23c-cfb1488289fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado = dados_redacoes.map(funcao_tokenizadora, batched=True, remove_columns=['essay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280dbef-12d4-4af3-9040-7c87eabab360",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0907d0-5567-4563-888a-64693117073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado['treino'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e960a-b622-4567-9701-e05be13454bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado['teste'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3049d7-002d-4cd4-8f9e-183104055b29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: Padding e Truncation\n",
    "\n",
    "Na utilização de dados textais, é muito comum que os textos tenham tamanhos variados. No entanto, as redes neurais geralmente exigem que os tensores utilizados como entradas tenham um tamanho fixo. Assim, ao converter textos em tokens, as entradas em lote podem ter comprimentos diferentes, o que pode gerar problemas de processamento e eficiência no modelo.\n",
    "\n",
    "Parar solucionar isso, são utilizadas técnicas como *padding* e *truncation*, que garantem que todas as sequências de entrada tenham um comprimento uniforme, permitindo que o modelo processe os dados de maneira consistente e eficiente. Vamos entender a diferença e usabilidade de cada um deles.\n",
    "\n",
    "#### Padding\n",
    "\n",
    "O padding é o processo de adicionar tokens (geralmente um token especial, como [PAD]) ao final ou ao início de uma sequência de texto para garantir que todas as sequências em um lote tenham o mesmo comprimento. Vamos entender isso a partir de um exemplo. Imagine que temos as seguintes sequências de texto:\n",
    "\n",
    "- “Eu gosto de aprender”\n",
    "- “Aprender é divertido”\n",
    "- “Estudar”\n",
    "\n",
    "Para processar essas sequências em um lote, precisamos que **todas tenham o mesmo comprimento**. Vamos supor que decidimos que todas devem ter 4 tokens. Aqui está como seria com padding, onde cada palavra é entendida como um token:\n",
    "\n",
    "- “Eu gosto de aprender”\n",
    "- “Aprender é divertido. [PAD]”\n",
    "- “Estudar. [PAD] [PAD] [PAD]”\n",
    "\n",
    "Dessa forma, todas as sequências têm o mesmo comprimento, facilitando o processamento em batch pelos modelos.\n",
    "\n",
    "#### Truncation\n",
    "\n",
    "O truncation é o processo de cortar uma sequência de texto para garantir que **ela não exceda um determinado comprimento**. Isso é útil quando temos textos muito longos e queremos garantir que todos os textos no lote tenham um comprimento máximo específico, economizando recursos computacionais e memória. Vamos utilizar o mesmo exemplo para entender como o truncation funciona.\n",
    "\n",
    "Imagine que temos as seguintes sequências de texto:\n",
    "\n",
    "- “Eu gosto de aprender”\n",
    "- “Aprender é divertido”\n",
    "- “Estudar”\n",
    "\n",
    "Se decidirmos que o comprimento máximo é de 3 tokens, o truncamento funcionaria assim:\n",
    "\n",
    "- “Eu gosto de” (truncado de “Eu gosto de aprender.”)\n",
    "- “Aprender é” (truncado de “Aprender é divertido.”)\n",
    "- “Estudar” (permanece o mesmo porque só tem 1 token)\n",
    "\n",
    "Caso queira entender sobre a utilização do padding e truncation da biblioteca Transformers, consulte a documentação:\n",
    "\n",
    "- [Padding and Truncation](https://huggingface.co/docs/transformers/pad_truncation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bb569-eec0-492f-80cb-92c9078f6a30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 03. Ajustando dados para o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1383bc53-8d2c-44ef-a99e-131d2e4d5128",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ajustando a variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5266e981-5cb2-41b8-83ac-d19f453b7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado['treino'].features['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff09021e-6d21-414b-9007-b462cba9a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394791aa-d877-497a-a919-c840f90e11a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado['treino'].unique('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ac921-cba4-4408-9306-822e7d4d0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = ClassLabel(names=[str(i) for i in range(11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7764cb01-df5d-4a27-9103-a6dc66cccb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c5d63-cb98-407f-be17-1f80fc35e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_labels(dados):\n",
    "    dados['label'] = scores.str2int(str(dados['score']))\n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801bc4b-a89e-46f7-8490-22df2d29bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado = dataset_tokenizado.map(mapear_labels, remove_columns='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c50a0bc-95de-4c1b-b972-2253405ace74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado = dataset_tokenizado.cast_column('label', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9d3cd-e113-4121-91a2-85b65ef4b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f50bb34-a0b9-43df-b6f1-6db831c37822",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tokenizado['treino'].features['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88adde1-a84d-488c-b50c-17804c6d9f61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Carregando o modelo pré-treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c99242-0d13-46eb-80ba-beef98d7e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce58ab8-c4e5-4c09-b5f3-2236ef99c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i: str(i) for i in range(11)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "modelo = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint_modelo,\n",
    "    num_labels = dataset_tokenizado['treino'].features['label'].num_classes,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    from_pt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875b866-b7a0-4989-97e9-935d45b57eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_treino = modelo.prepare_tf_dataset(\n",
    "    dataset_tokenizado['treino'],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    tokenizer=tokenizador\n",
    ")\n",
    "\n",
    "dados_validacao = modelo.prepare_tf_dataset(\n",
    "    dataset_tokenizado['teste'],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    tokenizer=tokenizador\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0844de-b0d6-4a4c-abed-8e5d31cd116e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: diferentes métodos de carregamento de modelos\n",
    "\n",
    "A biblioteca [`Transformers`](https://huggingface.co/docs/transformers/index) é uma ferramenta poderosa para o desenvolvimento de modelos de linguagem natural baseados em deep learning. Entre suas várias funcionalidades, as Auto Classes (Classes Automáticas) se destacam por simplificar e agilizar o uso de modelos pré-treinados, sendo capazes de identificar e carregar automaticamente o modelo correto com base em uma string identificadora do modelo. Vamos agora conhecer algumas.\n",
    "\n",
    "#### Principais Auto Classes\n",
    "\n",
    "- **AutoModel**: é utilizado para carregar modelos de aprendizado profundo para diversas tarefas de NLP (Processamento de Linguagem Natural). Ele automaticamente seleciona o tipo de modelo correto (como BERT, GPT-2, RoBERTa, etc.) baseado n onome do modelo fornecido.\n",
    "- **AutoTokenizer**: carrega o tokenizador correspondente ao modelo. O tokenizador é responsável por converter o texto bruto em tokens que o modelo pode processar.\n",
    "- **AutoConfig**: carrega a configuração do modelo, que contém parâmetros importantes como o número de camadas, tamanho do vocabulário, entre outros. É útil para inspeção ou para quando se deseja modificar algumas configurações antes de carregar o modelo.\n",
    "\n",
    "#### Auto Classes específicas\n",
    "\n",
    "Além das Auto Classes gerais, biblioteca também oferece várias Auto Classes específicas, cada uma projetada para diferentes tarefas de NLP. Considere a seguir as principais classes específicas e suas utilizações:\n",
    "\n",
    "- **AutoModelForSequenceClassification**: utilizada para tarefas de classificação de sequência, como análise de sentimentos, detecção de spam e classificação de tópicos.\n",
    "- **AutoModelForTokenClassification**: utilizada para tarefas de classificação de tokens, como reconhecimento de entidade nomeadas (NER) e marcação de partes do discurso (POS tagging).\n",
    "- **AutoModelForQuestionAnswering**: utilizada para sistemas de perguntas e respostas, onde o modelo responde a perguntas baseadas em um contexto fornecido.\n",
    "- **AutoModelForSeq2SeqLM**: utilizada para tarefas de tradução de linguagem, resumo de textos, e outras tarefas de sequência-para-sequência (seq2seq).\n",
    "- **AutoModelForCausalLM**: utilizada para tarefas de geração de texto, como modelos de linguagem autoregressivos (e.g., GPT-2, GPT-3).\n",
    "- **AutoModelForMaskedLM**: utilizada para tarefas de modelagem de linguagem com máscaras, como preenchimento de palavras mascaradas em um texto (e.g., BERT).\n",
    "- **AutoModelForMultipleChoice**: utilizada para tarefas de escolha múltipla, onde o modelo escolhe a resposta correta entre várias opções fornecidas.\n",
    "- **AutoModelForNextSentencePrediction**: utilizada para tarefas de predição da próxima sentença, como determinar se uma sentença segue logicamente outra.\n",
    "\n",
    "#### Vantagens das Auto Classes\n",
    "\n",
    "| **Benefício**           | **Descrição**                                                                                       |\n",
    "|-------------------------|-----------------------------------------------------------------------------------------------------|\n",
    "| **Simplicidade e Conveniência** | Elimina a necessidade de saber detalhes específicos sobre a arquitetura do modelo que se está carregando. Basta fornecer o nome do modelo. |\n",
    "| **Flexibilidade**       | Funciona com uma ampla gama de modelos diferentes, permitindo fácil troca entre diferentes arquiteturas e experimentação. |\n",
    "| **Consistência**        | Garante uma interface consistente, independente do modelo subjacente, o que facilita o desenvolvimento e a manutenção de código. |\n",
    "\n",
    "Caso queira conhecer mais sobre os AutoModels e todas as suas possibilidades, veja a documentação oficial da biblioteca Transformers:\n",
    "\n",
    "- [Auto Models - documentação Hugging Face](https://huggingface.co/docs/transformers/model_doc/auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f668a9-2664-46a2-94c1-ce1bd1239061",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 04. Transferindo o aprendizado para um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb2e42c-22a2-4c07-b966-d6ca09e47f71",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Treinando um modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb76d9-4560-4700-861f-17613bbd0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99009908-1c0c-417a-ba42-ec264c6c8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epocas = 2\n",
    "batches_por_epoca = len(dataset_tokenizado['treino']) // batch_size\n",
    "total_passos_treino = int(batches_por_epoca * epocas)\n",
    "taxa_aprendizado = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb4b40-6eaf-426d-9f1f-69aed4268641",
   "metadata": {},
   "outputs": [],
   "source": [
    "otimizador, scheduler = create_optimizer(\n",
    "    init_lr=taxa_aprendizado,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=total_passos_treino\n",
    ")\n",
    "\n",
    "modelo.compile(optimizer=otimizador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66955a8-9b29-48f7-918e-016ec98e6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(dados_treino, validation_data=dados_validacao, epochs=epocas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97529061-f585-446d-b4f7-48687ead2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_avaliacao = modelo.evaluate(dados_validacao)\n",
    "print(f\"Loss: {resultados_avaliacao}\")  # Loss: 1.6454880237579346"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0523b00-37d9-4336-a0ab-509ed467925d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Publicando o modelo no Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca6f47-b82a-4b4b-a12a-ff822192e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d3ef0-9159-4053-b06f-0d67ccf81c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.push_to_hub('distilbert-pt-cased-essays-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc333b4f-90da-4ed7-a1e3-7e3a9c0617d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizador.push_to_hub('distilbert-pt-cased-essays-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb0a90-90c2-45da-a1b0-06cc87ea6daa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 05. Colocando o modelo em produção"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff712ae-b4ce-40e3-947b-309a869bd8fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Utilizando o modelo para previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d25547e-b3e1-48ae-8f38-33a02d34c256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo = TFAutoModelForSequenceClassification.from_pretrained('c3p0gan/distilbert-pt-cased-essays-score')\n",
    "# tokenizador = AutoTokenizer.from_pretrained('c3p0gan/distilbert-pt-cased-essays-score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6113026a-7596-43f5-a629-2ad5fc58771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_redacoes['teste'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bd863-ea73-40c4-8e83-ba1d0eba903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = [dados_redacoes['teste']['essay'][2], dados_redacoes['teste']['essay'][909]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81860774-9891-4c6c-b201-64b93237e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab64968-d895-42c8-80ca-a4e0daf94017",
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_tokenizados = tokenizador(textos, return_tensors='np', padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1042671-8289-433a-ab05-49220ba7ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = modelo(textos_tokenizados).logits\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9eeae5-22cb-44a2-8912-7dc5fee27375",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacao = np.argmax(resultados, axis=1)\n",
    "print(classificacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06736f4-d8bf-4014-8eb6-cd86b45023a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = pipeline('text-classification', model='c3p0gan/distilbert-pt-cased-essays-score', framework='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29555b65-d5e7-48d0-8192-8263c9430fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador(textos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedc545-b026-4b28-b2ae-13d846d18563",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Para saber mais: resultado da previsão de um modelo de IA\n",
    "\n",
    "Quando um modelo de IA realiza uma previsão, geralmente não fornece diretamente uma classe ou uma probabilidade. Em vez disso, são gerados um conjunto de valores numéricos chamados **logits**. Os logits podem ser qualquer número real, positivo ou negativo, e indicam a força e a direção da previsão do modelo para cada classe possível.\n",
    "\n",
    "Para converter os logits em probabilidades compreensíveis, utiliza-se uma **função de ativação**. A mais comum é a softmax, que transforma os logits em valores entre 0 e 1, somando exatamente 1, tornando-os probabilidades (scores). Essas probabilidades indicam a confiança do modelo em cada classe.\n",
    "\n",
    "Logits são importantes porque:\n",
    "\n",
    "- Eles contêm informação sobre a confiança do modelo: logits mais altos indicam maior confiança.\n",
    "- Facilita o cálculo da métrica perda (Loss): funções de perda, como a entropia cruzada, usam logits para calcular o erro do modelo durante o treinamento.\n",
    "- Servem como base para a decisão final: antes de aplicar a função de ativação, os logits ajudam a entender como o modelo chega às suas conclusões."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf353f-150a-45ea-aa6a-a227dae21469",
   "metadata": {},
   "source": [
    "## Para ir mais a fundo\n",
    "\n",
    "[Transformers, documentação oficial](https://huggingface.co/docs/transformers/index)\n",
    "\n",
    "[Datasets, documentação oficial](https://huggingface.co/docs/datasets/index)\n",
    "\n",
    "[Gradio, documentação oficial](https://www.gradio.app/docs)\n",
    "\n",
    "[curso de NLP com Hugging Face](https://huggingface.co/learn/nlp-course/chapter1/1)\n",
    "\n",
    "[Notebooks de exemplos de projetos com Hugging Face, GitHub](https://github.com/huggingface/notebooks/tree/main/examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transferindo aprendizado (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
